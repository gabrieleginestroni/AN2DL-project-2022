{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Code for competition"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:55:56.541125Z","iopub.status.busy":"2022-11-17T21:55:56.540703Z","iopub.status.idle":"2022-11-17T21:59:09.339723Z","shell.execute_reply":"2022-11-17T21:59:09.338584Z","shell.execute_reply.started":"2022-11-17T21:55:56.541041Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libcudnn8-dev\n","The following held packages will be changed:\n","  libcudnn8\n","The following packages will be upgraded:\n","  libcudnn8 libcudnn8-dev\n","2 upgraded, 0 newly installed, 0 to remove and 91 not upgraded.\n","Need to get 883 MB of archives.\n","After this operation, 1429 MB disk space will be freed.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libcudnn8-dev 8.6.0.163-1+cuda11.8 [437 MB]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libcudnn8 8.6.0.163-1+cuda11.8 [446 MB]\n","Fetched 883 MB in 12s (73.3 MB/s)                                              \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n","\n","(Reading database ... 108827 files and directories currently installed.)\n","Preparing to unpack .../libcudnn8-dev_8.6.0.163-1+cuda11.8_amd64.deb ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking libcudnn8-dev (8.6.0.163-1+cuda11.8) over (8.0.5.39-1+cuda11.0) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Preparing to unpack .../libcudnn8_8.6.0.163-1+cuda11.8_amd64.deb ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking libcudnn8 (8.6.0.163-1+cuda11.8) over (8.0.5.39-1+cuda11.0) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Setting up libcudnn8 (8.6.0.163-1+cuda11.8) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up libcudnn8-dev (8.6.0.163-1+cuda11.8) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v8.h to provide /usr/include/cudnn.h (libcudnn) in auto mode\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\n","\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JFound existing installation: tensorflow 2.6.4\n","Uninstalling tensorflow-2.6.4:\n","  Successfully uninstalled tensorflow-2.6.4\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting tensorflow\n","  Downloading tensorflow-2.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.0)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.43.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow) (59.8.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n","Collecting keras<2.11,>=2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (4.1.1)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.1)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n","Collecting libclang>=13.0.0\n","  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting absl-py>=1.0.0\n","  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow) (21.3)\n","Collecting tensorflow-estimator<2.11,>=2.10.0\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.19.4)\n","Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.21.6)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.7)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow) (3.0.9)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.7)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.13.0)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.0)\n","Installing collected packages: libclang, keras, flatbuffers, tensorflow-io-gcs-filesystem, tensorflow-estimator, absl-py, tensorflow\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.6.0\n","    Uninstalling keras-2.6.0:\n","      Successfully uninstalled keras-2.6.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 1.12\n","    Uninstalling flatbuffers-1.12:\n","      Successfully uninstalled flatbuffers-1.12\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.6.0\n","    Uninstalling tensorflow-estimator-2.6.0:\n","      Successfully uninstalled tensorflow-estimator-2.6.0\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 0.15.0\n","    Uninstalling absl-py-0.15.0:\n","      Successfully uninstalled absl-py-0.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.10.1 which is incompatible.\n","tensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.10.1 which is incompatible.\n","tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, but you have tensorflow-io-gcs-filesystem 0.27.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed absl-py-1.3.0 flatbuffers-22.10.26 keras-2.10.0 libclang-14.0.6 tensorflow-2.10.1 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"name":"stderr","output_type":"stream","text":["2022-11-17 21:59:00.818664: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-11-17 21:59:01.002595: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-11-17 21:59:02.059397: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2022-11-17 21:59:02.059670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2022-11-17 21:59:02.059687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]},{"name":"stdout","output_type":"stream","text":["Thu Nov 17 21:59:06 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n","| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","2.10.1\n","[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"]},{"name":"stderr","output_type":"stream","text":["2022-11-17 21:59:07.087413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.088428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.220900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.221838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.222693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.223587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.227113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.228357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.231359: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-11-17 21:59:07.539407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.540464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.541306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.542088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.542867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:07.543730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:09.247476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:09.248362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:09.249214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:09.250197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:09.251005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:09.251726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13737 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","2022-11-17 21:59:09.252855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-11-17 21:59:09.253816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13737 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"]}],"source":["!apt -y install --allow-change-held-packages libcudnn8=8.6.0.163-1+cuda11.8\n","\n","!pip uninstall -y tensorflow \n","#!pip uninstall -y tensorflow-transform\n","#!pip uninstall -y tensorflow-io\n","#!pip install tensorflow-transform\n","!pip install tensorflow\n","\n","import tensorflow as tf\n","from tensorflow.keras import mixed_precision\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import os\n","import shutil\n","from collections import Counter\n","import random\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils import class_weight\n","from PIL import Image\n","import re\n","import time\n","from IPython.display import FileLink\n","\n","!nvidia-smi\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)\n","print(tf.config.list_physical_devices())\n","\n","# Enable experimental feature of memory occupation growth control \n","physical_devices = tf.config.experimental.list_physical_devices('GPU')\n","for dev in physical_devices:\n","    tf.config.experimental.set_memory_growth(dev, True)\n","    \n","# Enable mixed precision\n","mixed_precision.set_global_policy('mixed_float16')\n","\n","# Enable distributed training\n","strategy = tf.distribute.MirroredStrategy()\n","\n","# Random seed for reproducibility\n","seed = 42\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"]},{"cell_type":"markdown","metadata":{},"source":["### Metadata"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:09.343420Z","iopub.status.busy":"2022-11-17T21:59:09.342595Z","iopub.status.idle":"2022-11-17T21:59:09.351306Z","shell.execute_reply":"2022-11-17T21:59:09.350239Z","shell.execute_reply.started":"2022-11-17T21:59:09.343377Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["256\n"]}],"source":["classes = [\"Species1\", \"Species2\", \"Species3\", \"Species4\", \"Species5\", \"Species6\", \"Species7\", \"Species8\"]\n","input_shape = (96, 96, 3)\n","input_size = input_shape[:-1]\n","inflation_coeff = 1.5\n","\n","batch_size = 128 * strategy.num_replicas_in_sync\n","epochs = 400\n","\n","print(batch_size)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:09.353995Z","iopub.status.busy":"2022-11-17T21:59:09.353230Z","iopub.status.idle":"2022-11-17T21:59:19.826884Z","shell.execute_reply":"2022-11-17T21:59:19.825840Z","shell.execute_reply.started":"2022-11-17T21:59:09.353957Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['training_data_final', '.virtual_documents', '__notebook_source__.ipynb']\n"]}],"source":["path = os.getcwd()\n","if not os.path.exists(path+'/training_data_final'):\n","    shutil.copytree('../input/training-data-final/training_data_final', os.getcwd() + r'/training_data_final')\n","print(os.listdir(os.getcwd()))"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare the environment"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:19.831436Z","iopub.status.busy":"2022-11-17T21:59:19.831136Z","iopub.status.idle":"2022-11-17T21:59:20.182714Z","shell.execute_reply":"2022-11-17T21:59:20.181707Z","shell.execute_reply.started":"2022-11-17T21:59:19.831409Z"},"trusted":true},"outputs":[],"source":["train_split = 0.8\n","\n","path = os.getcwd()\n","if not os.path.exists(path+'/training') and not os.path.exists(path+'/validation'):\n","    os.mkdir(path+'/training')\n","    os.mkdir(path+'/validation')\n","\n","    # Destination path \n","    dest_train = path + '/training'\n","    dest_valid = path + '/validation'\n","\n","    # Source path\n","    source = path + '/training_data_final'\n","\n","    # Create train and validation into the training and validation folders\n","    for folder in os.listdir(source):\n","        if not os.path.exists(dest_train + '/' + folder):\n","            os.mkdir(dest_train + '/' + folder)\n","        if not os.path.exists(dest_valid + '/' + folder):\n","            os.mkdir(dest_valid + '/' + folder)\n","    \n","        class_source = source + '/' + folder                                                   # Create path of the class\n","        files = os.listdir(class_source)                                                       # List of files for the class\n","        random.shuffle(files)                                                                  # Split is performed randomly\n","        \n","        # Create training set randomly\n","        for i in range(int(len(files) * train_split)):\n","            dest = shutil.copy(class_source+'/'+files[i], dest_train+'/'+folder+'/'+files[i])  # Copy an image in the training set\n","        \n","        # Create validation set randomly\n","        for j in range(i + 1, len(files)):\n","            dest = shutil.copy(class_source+'/'+files[j], dest_valid+'/'+folder+'/'+files[j])  # copy an image in the validation set"]},{"cell_type":"markdown","metadata":{},"source":["### Preprocessing function"]},{"cell_type":"markdown","metadata":{},"source":["Allows us to simply define a pipeline of preprocessing transformations"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:20.184687Z","iopub.status.busy":"2022-11-17T21:59:20.184298Z","iopub.status.idle":"2022-11-17T21:59:20.193209Z","shell.execute_reply":"2022-11-17T21:59:20.192172Z","shell.execute_reply.started":"2022-11-17T21:59:20.184648Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.applications.xception import preprocess_input\n","\n","def preprocessing(image):\n","    #return tf.image.adjust_saturation(image, 3)\n","    return preprocess_input(image)\n","    #return image"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare the training set for standardization"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:20.196454Z","iopub.status.busy":"2022-11-17T21:59:20.195280Z","iopub.status.idle":"2022-11-17T21:59:22.476485Z","shell.execute_reply":"2022-11-17T21:59:22.475255Z","shell.execute_reply.started":"2022-11-17T21:59:20.196420Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(2829, 96, 96, 3), float32\n","(2829, 8), uint8\n","{0: 2.389358108108108, 1: 0.8320588235294117, 2: 0.8583131067961165, 3: 0.8667279411764706, 4: 0.8340212264150944, 5: 1.9978813559322033, 6: 0.8243006993006993, 7: 0.8709975369458128}\n"]}],"source":["samples = []\n","targets = []\n","\n","dest_train = os.getcwd() + '/training'\n","\n","for folder in os.listdir(dest_train):\n","    dest_class = dest_train + '/' + folder\n","    i = int(re.sub(\"\\D\", \"\", folder)) - 1\n","    for img in os.listdir(dest_class):\n","        temp = Image.open(dest_class + '/' + img).convert('RGB')\n","        image = preprocessing(np.squeeze(np.expand_dims(temp, axis=0)))\n","        label = tfk.utils.to_categorical(i, len(classes))\n","        samples.append(image)\n","        targets.append(label)\n","X_train = np.array(samples)\n","y_train = np.array(targets, dtype=np.uint8)\n","print(X_train.shape, X_train.dtype, sep=\", \")\n","print(y_train.shape, y_train.dtype, sep=\", \")\n","\n","# Compute the class weights in order to balance loss during training\n","y_numeric = []\n","for v in y_train:\n","    y_numeric.append(np.argmax(v))\n","\n","labels = np.unique(np.fromiter([np.argmax(t) for t in y_train], np.int32))\n","    \n","class_weights = dict(enumerate(class_weight.compute_class_weight('balanced', classes=labels, y=y_numeric)))\n","print(class_weights)"]},{"cell_type":"markdown","metadata":{},"source":["### Static augmentation (only on training set)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:22.479444Z","iopub.status.busy":"2022-11-17T21:59:22.478694Z","iopub.status.idle":"2022-11-17T21:59:29.630848Z","shell.execute_reply":"2022-11-17T21:59:29.629723Z","shell.execute_reply.started":"2022-11-17T21:59:22.479400Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 406 images belonging to 1 classes.\n","Computing 1310 augmented images for target \"Species8\"\n","Found 177 images belonging to 1 classes.\n","Computing 1110 augmented images for target \"Species6\"\n","Found 429 images belonging to 1 classes.\n","Computing 0 augmented images for target \"Species7\"\n","Found 425 images belonging to 1 classes.\n","Computing 4 augmented images for target \"Species2\"\n","Found 408 images belonging to 1 classes.\n","Computing 21 augmented images for target \"Species4\"\n","Found 148 images belonging to 1 classes.\n","Computing 2426 augmented images for target \"Species1\"\n","Found 412 images belonging to 1 classes.\n","Computing 17 augmented images for target \"Species3\"\n","Found 424 images belonging to 1 classes.\n","Computing 5 augmented images for target \"Species5\"\n","\n","/kaggle/working\n"]}],"source":["static_aug = True\n","balanced = False\n","\n","if static_aug and not os.path.exists(path+'/training_aug'):\n","    old_train = os.getcwd() + '/training'\n","    dest_train = os.getcwd() + '/training_aug'\n","    shutil.copytree(old_train, dest_train)\n","\n","    desired_amount = int(537 * train_split)\n","\n","    static_gen = ImageDataGenerator()\n","\n","    for folder in os.listdir(dest_train):\n","        dest_path = dest_train + '/' + folder\n","        label = int(re.sub(\"\\D\", \"\", folder)) - 1\n","\n","        if balanced:\n","            to_produce = desired_amount - len(os.listdir(dest_path))\n","        else:\n","            class_expansion = [6, 1, 1, 1, 1, 3, 1, 4]\n","            to_produce = (class_expansion[label] * desired_amount) - len(os.listdir(dest_path))\n","        \n","        static_gen_data = static_gen.flow_from_directory(dest_train,\n","                                                        batch_size=1,\n","                                                        target_size=input_size,\n","                                                        classes=[folder],\n","                                                        class_mode='categorical',      # Targets are directly converted into one-hot vectors\n","                                                        shuffle=False,\n","                                                        seed=seed) \n","\n","        print(f'Computing {to_produce} augmented images for target \"{folder}\"')\n","        os.chdir(dest_path)\n","        for i in range(0, to_produce):\n","            Image.fromarray(np.squeeze(next(static_gen_data)[0]).astype(np.uint8)).save(f'aug{i:05}.jpg')\n","        os.chdir('../')\n","\n","    os.chdir('../')\n","    print('\\n' + os.getcwd())"]},{"cell_type":"markdown","metadata":{},"source":["### Online augmentation\n","Lets create the generators we'll need..."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:29.632944Z","iopub.status.busy":"2022-11-17T21:59:29.632560Z","iopub.status.idle":"2022-11-17T21:59:29.639807Z","shell.execute_reply":"2022-11-17T21:59:29.638542Z","shell.execute_reply.started":"2022-11-17T21:59:29.632905Z"},"trusted":true},"outputs":[],"source":["shift = 30\n","train_data_gen = ImageDataGenerator(rotation_range=90,\n","                                    width_shift_range=shift,\n","                                    height_shift_range=shift,\n","                                    horizontal_flip=True,\n","                                    brightness_range=(0.8, 1.05),\n","                                    #channel_shift_range=150,\n","                                    zoom_range=[0.8, 1.3],\n","                                    shear_range=0.1,\n","                                    fill_mode='reflect',\n","                                    preprocessing_function=preprocessing\n","                                    #featurewise_std_normalization=True,\n","                                    #featurewise_center=True, \n","                                    #rescale=1./255\n","                                    )\n","\n","valid_data_gen = ImageDataGenerator(preprocessing_function=preprocessing\n","                                    #featurewise_std_normalization=True,\n","                                    #featurewise_center=True, \n","                                    #rescale=1./255\n","                                    )\n","\n","# Fit the standardization values\n","#train_data_gen.fit(X_train)\n","#valid_data_gen.fit(X_train)"]},{"cell_type":"markdown","metadata":{},"source":["... using flow_from_directory"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:29.642396Z","iopub.status.busy":"2022-11-17T21:59:29.641676Z","iopub.status.idle":"2022-11-17T21:59:30.038497Z","shell.execute_reply":"2022-11-17T21:59:30.037558Z","shell.execute_reply.started":"2022-11-17T21:59:29.642361Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 7722 images belonging to 8 classes.\n","Found 713 images belonging to 8 classes.\n"]}],"source":["# Setting right paths\n","path = os.getcwd()\n","if static_aug:\n","    training_dir = path + '/training_aug'\n","else:\n","    training_dir = path + '/training'\n","validation_dir = path + '/validation'\n","\n","# Training\n","train_gen = train_data_gen.flow_from_directory(training_dir,\n","                                               batch_size=batch_size,\n","                                               target_size=input_size,\n","                                               classes=classes,\n","                                               class_mode='categorical',\n","                                               shuffle=True,\n","                                               seed=seed)  \n","\n","# Validation\n","valid_gen = valid_data_gen.flow_from_directory(validation_dir,\n","                                               batch_size=batch_size, \n","                                               target_size=input_size,\n","                                               classes=classes,\n","                                               class_mode='categorical',\n","                                               shuffle=False,\n","                                               seed=seed)\n","\n","# Disable AutoShard\n","options = tf.data.Options()\n","options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n","\n","# Create Datasets objects\n","train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n","                                               output_types=(tf.float16, tf.uint8),\n","                                               output_shapes=([None, input_shape[0], input_shape[1], input_shape[2]], [None, len(classes)]))\n","\n","train_dataset = train_dataset.with_options(options)\n","train_dataset = train_dataset.repeat()\n","\n","valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n","                                               output_types=(tf.float16, tf.uint8),\n","                                               output_shapes=([None, input_shape[0], input_shape[1], input_shape[2]], [None, len(classes)]))\n","\n","valid_dataset = valid_dataset.with_options(options)\n","valid_dataset = valid_dataset.repeat()"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare the validation set for evaluation purposes"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:30.042646Z","iopub.status.busy":"2022-11-17T21:59:30.042356Z","iopub.status.idle":"2022-11-17T21:59:30.643801Z","shell.execute_reply":"2022-11-17T21:59:30.642581Z","shell.execute_reply.started":"2022-11-17T21:59:30.042619Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(713, 96, 96, 3), float16\n","(713, 8), uint8\n"]}],"source":["samples = []\n","targets = []\n","\n","#mean = train_data_gen.mean\n","#std = train_data_gen.std\n","\n","dest_valid = os.getcwd() + '/validation'\n","\n","for folder in os.listdir(dest_valid):\n","    dest_class = dest_valid + '/' + folder\n","    i = int(re.sub(\"\\D\", \"\", folder)) - 1\n","    for img in os.listdir(dest_class):\n","        temp = Image.open(dest_class + '/' + img).convert('RGB')\n","        #image = preprocessing((np.squeeze(np.expand_dims(temp, axis=0)) - mean) / std)\n","        image = preprocessing(np.squeeze(np.expand_dims(temp, axis=0)))\n","        label = tfk.utils.to_categorical(i, len(classes))\n","        samples.append(image)\n","        targets.append(label)\n","\n","X_val = np.array(samples, dtype=np.float16)\n","y_val = np.array(targets, dtype=np.uint8)\n","print(X_val.shape, X_val.dtype, sep=\", \")\n","print(y_val.shape, y_val.dtype, sep=\", \")"]},{"cell_type":"markdown","metadata":{},"source":["### Models definition functions"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:30.645959Z","iopub.status.busy":"2022-11-17T21:59:30.645259Z","iopub.status.idle":"2022-11-17T21:59:30.655393Z","shell.execute_reply":"2022-11-17T21:59:30.654337Z","shell.execute_reply.started":"2022-11-17T21:59:30.645919Z"},"trusted":true},"outputs":[],"source":["def build_tl_model(input_shape):\n","    tf.random.set_seed(seed)\n","    \n","    inflated_dim0 = int(inflation_coeff * input_shape[0])\n","    inflated_dim1 = int(inflation_coeff * input_shape[1])\n","    inflated_shape = (inflated_dim0, inflated_dim1, 3)\n","\n","    # Load the supernet\n","    supernet = tfk.applications.Xception(include_top=False,\n","                                         weights=\"imagenet\",\n","                                         input_shape=inflated_shape)\n","    \n","    # Build the neural network layer by layer\n","    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n","    \n","    x = tfkl.Resizing(inflated_dim0, inflated_dim1, interpolation=\"bicubic\", name='resizing')(input_layer)\n","    \n","    x = supernet(x)\n","\n","    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n","    #x = tfkl.Flatten(name='flatten')(x)\n","\n","    x = tfkl.Dropout(0.3, seed=seed, name='dropout')(x)\n","    \n","    output_layer = tfkl.Dense(\n","        units = len(classes), \n","        activation = 'softmax', \n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        name = 'output_layer')(x)\n","    \n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs = input_layer, outputs = output_layer, name = 'tl_model')\n","\n","    # Compile the model\n","    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(2e-4), metrics='accuracy')\n","\n","    # Return the model\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["### Build the model"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:30.658384Z","iopub.status.busy":"2022-11-17T21:59:30.656724Z","iopub.status.idle":"2022-11-17T21:59:35.909155Z","shell.execute_reply":"2022-11-17T21:59:35.908089Z","shell.execute_reply.started":"2022-11-17T21:59:30.658354Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83683744/83683744 [==============================] - 0s 0us/step\n","Model: \"tl_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_layer (InputLayer)    [(None, 96, 96, 3)]       0         \n","                                                                 \n"," resizing (Resizing)         (None, 144, 144, 3)       0         \n","                                                                 \n"," xception (Functional)       (None, 5, 5, 2048)        20861480  \n","                                                                 \n"," gap (GlobalAveragePooling2D  (None, 2048)             0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 2048)              0         \n","                                                                 \n"," output_layer (Dense)        (None, 8)                 16392     \n","                                                                 \n","=================================================================\n","Total params: 20,877,872\n","Trainable params: 20,823,344\n","Non-trainable params: 54,528\n","_________________________________________________________________\n"]}],"source":["with strategy.scope():\n","    model = build_tl_model(input_shape)\n","    model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### Train the model"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T21:59:35.911651Z","iopub.status.busy":"2022-11-17T21:59:35.910898Z","iopub.status.idle":"2022-11-17T22:02:51.407903Z","shell.execute_reply":"2022-11-17T22:02:51.406021Z","shell.execute_reply.started":"2022-11-17T21:59:35.911611Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/400\n"]},{"name":"stderr","output_type":"stream","text":["2022-11-17 22:00:11.133040: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n","2022-11-17 22:00:11.617274: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n","2022-11-17 22:00:12.775118: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n","\n","You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n","2022-11-17 22:00:13.863256: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n","\n","You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"]},{"name":"stdout","output_type":"stream","text":["31/31 [==============================] - ETA: 0s - loss: 1.8707 - accuracy: 0.4628\n","Elapsed time: 1 minutes 19.922 seconds\n","31/31 [==============================] - 81s 1s/step - loss: 1.8707 - accuracy: 0.4628 - val_loss: 2.1039 - val_accuracy: 0.2398 - lr: 2.0000e-04\n","Epoch 2/400\n","31/31 [==============================] - ETA: 0s - loss: 0.8841 - accuracy: 0.6966\n","Elapsed time: 1 minutes 53.883 seconds\n","31/31 [==============================] - 34s 1s/step - loss: 0.8841 - accuracy: 0.6966 - val_loss: 1.6262 - val_accuracy: 0.4670 - lr: 2.0000e-04\n","Epoch 3/400\n","31/31 [==============================] - ETA: 0s - loss: 0.5711 - accuracy: 0.8087\n","Elapsed time: 2 minutes 29.730 seconds\n","31/31 [==============================] - 36s 1s/step - loss: 0.5711 - accuracy: 0.8087 - val_loss: 1.5818 - val_accuracy: 0.4881 - lr: 2.0000e-04\n","Epoch 4/400\n","31/31 [==============================] - ETA: 0s - loss: 0.4112 - accuracy: 0.8592\n","Elapsed time: 3 minutes 5.830 seconds\n","31/31 [==============================] - 36s 1s/step - loss: 0.4112 - accuracy: 0.8592 - val_loss: 1.4007 - val_accuracy: 0.5820 - lr: 2.0000e-04\n","Epoch 5/400\n"," 7/31 [=====>........................] - ETA: 26s - loss: 0.3294 - accuracy: 0.8934"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/1353397242.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=21, restore_best_weights=True),\n\u001b[1;32m     25\u001b[0m                                  \u001b[0mtfk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                  ElapsedTimeCallback()]\n\u001b[0m\u001b[1;32m     27\u001b[0m ).history\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                         ):\n\u001b[1;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2497\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1863\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_mul = 1\n","\n","'''\n","high_period = 5\n","medium_period = 10\n","low_period = 5\n","\n","high_lr = 5e-4  \n","medium_lr = 1e-4\n","low_lr = 2e-5\n","\n","def scheduler(epoch, lr):\n","    global medium_lr, high_lr\n","\n","    #convergence factor to shrink high and medium values onto low_lr over time\n","    tot_period = high_period + medium_period + low_period + medium_period\n","    if epoch % (tot_period) == (tot_period - 1):\n","        high_lr = max(high_lr * tf.math.exp(-0.1), low_lr)\n","        medium_lr = max(medium_lr * tf.math.exp(-0.1), low_lr)\n","\n","    if epoch % (tot_period) < high_period:\n","        return high_lr\n","    elif epoch % (tot_period) < high_period + medium_period:\n","        return medium_lr    \n","    elif epoch % (tot_period) < high_period + medium_period + low_period:\n","        return low_lr    \n","    return medium_lr\n","'''\n","\n","decay_rate = 5  # patience should be set: changes_to_see * decay_rate + 1\n","min_lr = 2e-5\n","\n","def scheduler(epoch, lr):\n","    if epoch % decay_rate == (decay_rate - 1):\n","        return max(lr * tf.math.exp(-0.1), min_lr)\n","    return lr\n","\n","start = time.time()\n","\n","class ElapsedTimeCallback(tfk.callbacks.Callback):\n","    def on_test_end(self, epoch, logs=None):\n","        el = time.time() - start\n","        print(f'\\nElapsed time: {int(el // 60)} minutes {(el % 60):.3f} seconds')\n","\n","history = model.fit(x=train_dataset,\n","                    epochs=epochs,                                     # Only indicative since we set \"repeat\" in training and validation datasets\n","                    steps_per_epoch=int(len(train_gen) * train_mul),\n","                    validation_data=valid_dataset,\n","                    validation_steps=len(valid_gen),\n","                    class_weight=class_weights,\n","                    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=21, restore_best_weights=True),\n","                                 tfk.callbacks.LearningRateScheduler(scheduler),\n","                                 ElapsedTimeCallback()]\n",").history"]},{"cell_type":"markdown","metadata":{},"source":["### Plot training results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:02:51.409307Z","iopub.status.idle":"2022-11-17T22:02:51.410251Z","shell.execute_reply":"2022-11-17T22:02:51.409969Z","shell.execute_reply.started":"2022-11-17T22:02:51.409927Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(15,5))\n","plt.plot(history['loss'], label='Std training', alpha=.3, color='#ff7f0e', linestyle='--')\n","plt.plot(history['val_loss'], label='Std validation', alpha=.8, color='#ff7f0e')\n","plt.legend(loc='upper left')\n","plt.title('Categorical Crossentropy')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(15,5))\n","plt.plot(history['accuracy'], label='Std training', alpha=.8, color='#ff7f0e', linestyle='--')\n","plt.plot(history['val_accuracy'], label='Std validation', alpha=.8, color='#ff7f0e')\n","plt.legend(loc='upper right')\n","plt.title('Accuracy')\n","plt.grid(alpha=.3)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Plot the confusion matrix (evaluated on the validation set)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:02:51.411901Z","iopub.status.idle":"2022-11-17T22:02:51.414080Z","shell.execute_reply":"2022-11-17T22:02:51.413798Z","shell.execute_reply.started":"2022-11-17T22:02:51.413769Z"},"trusted":true},"outputs":[],"source":["predictions = model.predict(X_val)\n","cm = confusion_matrix(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\n","\n","accuracy = accuracy_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\n","precision = precision_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n","recall = recall_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n","f1 = f1_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average=None)\n","print('Accuracy:',accuracy.round(4))\n","print('Precision:',precision.round(4))\n","print('Recall:',recall.round(4))\n","print('F1:',f1.round(4))\n","\n","plt.figure(figsize=(10,8))\n","sns.heatmap(cm.T, xticklabels=classes, yticklabels=classes)\n","plt.xlabel('True labels')\n","plt.ylabel('Predicted labels')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Save the model"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T22:03:01.539048Z","iopub.status.busy":"2022-11-17T22:03:01.538311Z","iopub.status.idle":"2022-11-17T22:03:29.919523Z","shell.execute_reply":"2022-11-17T22:03:29.918546Z","shell.execute_reply.started":"2022-11-17T22:03:01.538989Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='best_model.zip' target='_blank'>best_model.zip</a><br>"],"text/plain":["/kaggle/working/best_model.zip"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["model.save('best_model', include_optimizer=False)\n","\n","shutil.make_archive('best_model', 'zip', 'best_model')\n","FileLink(r'best_model.zip')"]},{"cell_type":"markdown","metadata":{},"source":["### Improve the classifier module of the previously trained supernet"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T22:10:45.336491Z","iopub.status.busy":"2022-11-17T22:10:45.336113Z","iopub.status.idle":"2022-11-17T22:10:45.349200Z","shell.execute_reply":"2022-11-17T22:10:45.348003Z","shell.execute_reply.started":"2022-11-17T22:10:45.336460Z"},"trusted":true},"outputs":[],"source":["def build_classifier_model(input_shape):\n","    tf.random.set_seed(seed)\n","    \n","    inflated_dim0 = int(inflation_coeff * input_shape[0])\n","    inflated_dim1 = int(inflation_coeff * input_shape[1])\n","    inflated_shape = (inflated_dim0, inflated_dim1, 3)\n","\n","    # Load the supernet\n","    supernet = tfk.applications.Xception(include_top=False,\n","                                         input_shape=inflated_shape)\n","\n","    # Recover previous weights\n","    supernet.set_weights(tfk.models.load_model('best_model').get_layer('xception').get_weights())\n","    \n","    # Use the supernet only as feature extractor\n","    supernet.trainable = False  # \"True\" for fine tuning\n","    for i, layer in enumerate(supernet.layers[:-25]):\n","      layer.trainable = False\n","      #print(i, layer.name, layer.trainable)\n","    \n","    # Build the neural network layer by layer\n","    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n","    \n","    x = tfkl.Resizing(inflated_dim0, inflated_dim1, interpolation=\"bicubic\", name='resizing')(input_layer)\n","    \n","    x = supernet(x)\n","\n","    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n","    \n","    x_gap = x\n","\n","    x = tfkl.Dropout(0.3, seed=seed, name='dropout')(x)\n","\n","    x = tfkl.Dense(\n","        units = 2048,  \n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.HeUniform(seed),\n","        name = 'classifier')(x)\n","\n","    # Skip connection\n","    x = tfkl.Add(name='adder')([x_gap, x])\n","    \n","    output_layer = tfkl.Dense(\n","                   units = len(classes), \n","                   activation = 'softmax', \n","                   kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","                   name = 'output_layer')(x)\n","    \n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs = input_layer, outputs = output_layer, name = 'classifier_model')\n","\n","    # Compile the model\n","    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(3e-4), metrics='accuracy')\n","\n","    # Return the model\n","    return model"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T22:10:50.121180Z","iopub.status.busy":"2022-11-17T22:10:50.120808Z","iopub.status.idle":"2022-11-17T22:11:05.349255Z","shell.execute_reply":"2022-11-17T22:11:05.348258Z","shell.execute_reply.started":"2022-11-17T22:10:50.121149Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"classifier_model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_layer (InputLayer)       [(None, 96, 96, 3)]  0           []                               \n","                                                                                                  \n"," resizing (Resizing)            (None, 144, 144, 3)  0           ['input_layer[0][0]']            \n","                                                                                                  \n"," xception (Functional)          (None, 5, 5, 2048)   20861480    ['resizing[0][0]']               \n","                                                                                                  \n"," gap (GlobalAveragePooling2D)   (None, 2048)         0           ['xception[0][0]']               \n","                                                                                                  \n"," dropout (Dropout)              (None, 2048)         0           ['gap[0][0]']                    \n","                                                                                                  \n"," classifier2 (Dense)            (None, 2048)         4196352     ['dropout[0][0]']                \n","                                                                                                  \n"," adder (Add)                    (None, 2048)         0           ['gap[0][0]',                    \n","                                                                  'classifier2[0][0]']            \n","                                                                                                  \n"," output_layer (Dense)           (None, 8)            16392       ['adder[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 25,074,224\n","Trainable params: 4,212,744\n","Non-trainable params: 20,861,480\n","__________________________________________________________________________________________________\n"]}],"source":["with strategy.scope():\n","    classifier_model = build_classifier_model(input_shape)\n","    classifier_model.summary()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-11-17T22:11:41.908247Z","iopub.status.busy":"2022-11-17T22:11:41.907882Z","iopub.status.idle":"2022-11-17T22:12:56.948888Z","shell.execute_reply":"2022-11-17T22:12:56.944939Z","shell.execute_reply.started":"2022-11-17T22:11:41.908215Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/400\n","31/31 [==============================] - ETA: 0s - loss: 0.6699 - accuracy: 0.7919\n","Elapsed time: 0 minutes 47.277 seconds\n"]},{"name":"stderr","output_type":"stream","text":["2022-11-17 22:12:29.813868: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 16777216 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 48s 1s/step - loss: 0.6699 - accuracy: 0.7919 - val_loss: 0.8404 - val_accuracy: 0.7209 - lr: 3.0000e-04\n","Epoch 2/400\n"]},{"name":"stderr","output_type":"stream","text":["2022-11-17 22:12:30.296165: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 16777216 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["29/31 [===========================>..] - ETA: 1s - loss: 0.4550 - accuracy: 0.8473"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/3570145466.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                           callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=26, restore_best_weights=True),\n\u001b[1;32m     12\u001b[0m                                                        \u001b[0mtfk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                                        ElapsedTimeCallback()]\n\u001b[0m\u001b[1;32m     14\u001b[0m ).history\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                         ):\n\u001b[1;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2497\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1863\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_mul = 1\n","\n","start = time.time()\n","\n","classifier_history = classifier_model.fit(x=train_dataset,\n","                                          epochs=epochs,                                  \n","                                          steps_per_epoch=int(len(train_gen) * train_mul),\n","                                          validation_data=valid_dataset,\n","                                          validation_steps=len(valid_gen),\n","                                          class_weight=class_weights,\n","                                          callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=26, restore_best_weights=True),\n","                                                       tfk.callbacks.LearningRateScheduler(scheduler),\n","                                                       ElapsedTimeCallback()]\n",").history"]},{"cell_type":"markdown","metadata":{},"source":["### Plot training results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:02:51.435285Z","iopub.status.idle":"2022-11-17T22:02:51.435792Z","shell.execute_reply":"2022-11-17T22:02:51.435525Z","shell.execute_reply.started":"2022-11-17T22:02:51.435488Z"},"trusted":true},"outputs":[],"source":["history = classifier_history\n","\n","plt.figure(figsize=(15,5))\n","plt.plot(history['loss'], label='Std training', alpha=.3, color='#ff7f0e', linestyle='--')\n","plt.plot(history['val_loss'], label='Std validation', alpha=.8, color='#ff7f0e')\n","plt.legend(loc='upper left')\n","plt.title('Categorical Crossentropy')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(15,5))\n","plt.plot(history['accuracy'], label='Std training', alpha=.8, color='#ff7f0e', linestyle='--')\n","plt.plot(history['val_accuracy'], label='Std validation', alpha=.8, color='#ff7f0e')\n","plt.legend(loc='upper right')\n","plt.title('Accuracy')\n","plt.grid(alpha=.3)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Plot the confusion matrix (evaluated on the validation set)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:02:51.439336Z","iopub.status.idle":"2022-11-17T22:02:51.439894Z","shell.execute_reply":"2022-11-17T22:02:51.439636Z","shell.execute_reply.started":"2022-11-17T22:02:51.439610Z"},"trusted":true},"outputs":[],"source":["predictions = classifier_model.predict(X_val)\n","cm = confusion_matrix(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\n","\n","accuracy = accuracy_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\n","precision = precision_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n","recall = recall_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n","f1 = f1_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average=None)\n","print('Accuracy:',accuracy.round(4))\n","print('Precision:',precision.round(4))\n","print('Recall:',recall.round(4))\n","print('F1:',f1.round(4))\n","\n","plt.figure(figsize=(10,8))\n","sns.heatmap(cm.T, xticklabels=classes, yticklabels=classes)\n","plt.xlabel('True labels')\n","plt.ylabel('Predicted labels')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Save the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:02:51.447340Z","iopub.status.idle":"2022-11-17T22:02:51.447962Z","shell.execute_reply":"2022-11-17T22:02:51.447660Z","shell.execute_reply.started":"2022-11-17T22:02:51.447631Z"},"trusted":true},"outputs":[],"source":["classifier_model.save('best_model_improved', include_optimizer=False)\n","\n","shutil.make_archive('best_model_improved', 'zip', 'best_model_improved')\n","FileLink(r'best_model_improved.zip')"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 ('anndl')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"830302ffa9751c9d00ec7acc7b0cf1db10db4d450fa3f08a82573b165c9771b0"}}},"nbformat":4,"nbformat_minor":4}
