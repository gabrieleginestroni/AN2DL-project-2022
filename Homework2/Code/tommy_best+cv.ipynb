{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### General imports and definitions","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport joblib\nimport shutil\nimport random\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.utils import class_weight\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nplt.rc('font', size=16) \n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)\nprint(tf.config.list_physical_devices())","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:11.589266Z","iopub.execute_input":"2022-12-18T15:18:11.589690Z","iopub.status.idle":"2022-12-18T15:18:13.826542Z","shell.execute_reply.started":"2022-12-18T15:18:11.589596Z","shell.execute_reply":"2022-12-18T15:18:13.825311Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"2.6.4\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"},{"name":"stderr","text":"2022-12-18 15:18:13.808469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-18 15:18:13.818694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-18 15:18:13.819451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Suppress warnings","metadata":{}},{"cell_type":"code","source":"import warnings\nimport logging\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\ntf.get_logger().setLevel('INFO')\ntf.autograph.set_verbosity(0)\n\ntf.get_logger().setLevel(logging.ERROR)\ntf.get_logger().setLevel('ERROR')\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:13.828848Z","iopub.execute_input":"2022-12-18T15:18:13.829854Z","iopub.status.idle":"2022-12-18T15:18:13.836322Z","shell.execute_reply.started":"2022-12-18T15:18:13.829815Z","shell.execute_reply":"2022-12-18T15:18:13.835662Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Set seed for reproducibility","metadata":{}},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:13.838117Z","iopub.execute_input":"2022-12-18T15:18:13.838757Z","iopub.status.idle":"2022-12-18T15:18:13.848415Z","shell.execute_reply.started":"2022-12-18T15:18:13.838720Z","shell.execute_reply":"2022-12-18T15:18:13.847451Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"#### Load and clean the dataset","metadata":{}},{"cell_type":"code","source":"# Load the .npy file\nX = np.load(r'../input/training/x_train.npy').astype(np.float32)\ny = np.load(r'../input/training/y_train.npy').astype(np.int8)\n\n# Leave a copy of numerical y\ny_num = np.copy(y)\n\n# Note as sequences are already built, with window 36\nprint(X.shape, X.dtype, sep=\", \")   \nprint(y.shape, y.dtype, sep=\", \") ","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:13.851072Z","iopub.execute_input":"2022-12-18T15:18:13.851456Z","iopub.status.idle":"2022-12-18T15:18:13.867799Z","shell.execute_reply.started":"2022-12-18T15:18:13.851421Z","shell.execute_reply":"2022-12-18T15:18:13.866794Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(2429, 36, 6), float32\n(2429,), int8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Drop features","metadata":{}},{"cell_type":"code","source":"def keep_only(X, features_list):\n    n_instances, n_timestamps, n_features = X.shape\n    X = np.reshape(X, newshape=(-1, n_features))\n    temp = np.empty((n_instances * n_timestamps, len(features_list)))\n    \n    i = 0\n    for f in features_list:\n        temp[:, i] = X[:, f]\n        i += 1\n    \n    temp = np.reshape(temp, newshape=(n_instances, n_timestamps, len(features_list)))\n    return temp\n\ndrop = False\n\nif drop:\n    X = keep_only(X, [1, 2, 3, 4, 5])\n    \nprint(X.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:13.870290Z","iopub.execute_input":"2022-12-18T15:18:13.870814Z","iopub.status.idle":"2022-12-18T15:18:13.887749Z","shell.execute_reply.started":"2022-12-18T15:18:13.870750Z","shell.execute_reply":"2022-12-18T15:18:13.885524Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(2429, 36, 6)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Compute the class weights in order to balance loss during training\nlabels = np.unique(np.fromiter([t for t in y], np.int32))\nclass_weights = dict(enumerate(class_weight.compute_class_weight('balanced', classes=labels, y=y)))\nprint(class_weights, '\\n')\n\n# Convert the sparse labels to categorical values\ny = tfk.utils.to_categorical(y)\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:13.890975Z","iopub.execute_input":"2022-12-18T15:18:13.891725Z","iopub.status.idle":"2022-12-18T15:18:13.927652Z","shell.execute_reply.started":"2022-12-18T15:18:13.891686Z","shell.execute_reply":"2022-12-18T15:18:13.926642Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{0: 5.953431372549019, 1: 1.6456639566395663, 2: 0.7496913580246913, 3: 0.5312773403324584, 4: 3.264784946236559, 5: 1.3229847494553377, 6: 0.6466986155484558, 7: 2.9767156862745097, 8: 1.6868055555555554, 9: 0.2605105105105105, 10: 2.628787878787879, 11: 3.968954248366013} \n\n(1943, 36, 6) (1943, 12)\n(486, 36, 6) (486, 12)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Metadata","metadata":{}},{"cell_type":"code","source":"classes = y_train.shape[-1]\nlabel_mapping = {\n    'Wish': 0,\n    'Another': 1,\n    'Comfortably': 2,\n    'Money': 3,\n    'Breathe': 4,\n    'Time': 5,\n    'Brain': 6,\n    'Echoes': 7,\n    'Wearing': 8,\n    'Sorrow': 9,\n    'Hey': 10,\n    'Shine': 11,  \n}\n\n# For training\nbatch_size = 2048\nepochs = 1000\n\n# Define the scaler we intend to use\nscaler = StandardScaler()\n\n# Define the PCA\nfinal_dim = 5\npca = PCA(n_components=final_dim, random_state=42)\n\n# Define the K-fold Cross Validator\nnum_folds = 10\nkfold = StratifiedKFold(n_splits=num_folds, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:13.930629Z","iopub.execute_input":"2022-12-18T15:18:13.930887Z","iopub.status.idle":"2022-12-18T15:18:13.940326Z","shell.execute_reply.started":"2022-12-18T15:18:13.930863Z","shell.execute_reply":"2022-12-18T15:18:13.939311Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### Data scaling","metadata":{}},{"cell_type":"code","source":"def scale(X_train, X_test, scaler, pca):\n    n_instances_train = X_train.shape[0]\n    X_train = np.reshape(X_train, newshape=(-1, 6))\n    X_train = scaler.fit_transform(X_train)\n    X_train = pca.fit_transform(X_train)\n    X_train = np.reshape(X_train, newshape=(n_instances_train, 36, final_dim))\n    \n    if X_test is not None:\n        n_instances_test = X_test.shape[0]\n        X_test = np.reshape(X_test, newshape=(-1, 6))\n        X_test = scaler.transform(X_test)\n        X_test = pca.transform(X_test)\n        X_test = np.reshape(X_test, newshape=(n_instances_test, 36, final_dim))\n        return X_train, X_test\n    \n    return X_train, None\n\nscaling = True\n\nif scaling:\n    X_train, X_test = scale(X_train, X_test, scaler, pca)\n    \nprint(X_train.shape, X_train.dtype)\nprint(X_test.shape, X_test.dtype)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:13.942549Z","iopub.execute_input":"2022-12-18T15:18:13.942883Z","iopub.status.idle":"2022-12-18T15:18:14.000108Z","shell.execute_reply.started":"2022-12-18T15:18:13.942857Z","shell.execute_reply":"2022-12-18T15:18:13.998747Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(1943, 36, 5) float32\n(486, 36, 5) float32\n","output_type":"stream"}]},{"cell_type":"code","source":"input_shape = X_train.shape[1:]\nn_timestamps, n_features = input_shape","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:14.005905Z","iopub.execute_input":"2022-12-18T15:18:14.009866Z","iopub.status.idle":"2022-12-18T15:18:14.020054Z","shell.execute_reply.started":"2022-12-18T15:18:14.009808Z","shell.execute_reply":"2022-12-18T15:18:14.018834Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### Support functions","metadata":{}},{"cell_type":"code","source":"def plot_history(history):\n    best_epoch = np.argmax(history['val_accuracy'])\n    plt.figure(figsize=(17,4))\n    plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n    plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n    plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n    plt.title('Categorical Crossentropy')\n    plt.legend()\n    plt.grid(alpha=.3)\n    plt.show()\n\n    plt.figure(figsize=(17,4))\n    plt.plot(history['accuracy'], label='Training accuracy', alpha=.8, color='#ff7f0e')\n    plt.plot(history['val_accuracy'], label='Validation accuracy', alpha=.9, color='#5a9aa5')\n    plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n    plt.title('Accuracy')\n    plt.legend()\n    plt.grid(alpha=.3)\n    plt.show()\n\n    plt.figure(figsize=(17,4))\n    plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n    plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n    plt.legend()\n    plt.grid(alpha=.3)\n    plt.show()\n\ndef plot_cm(model):\n    # Predict the test set with the LSTM\n    predictions = model.predict(X_test)\n    predictions.shape\n\n    # Compute the confusion matrix\n    cm = confusion_matrix(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1))\n\n    # Compute the classification metrics\n    accuracy = accuracy_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1))\n    precision = precision_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n    recall = recall_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n    f1 = f1_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average=None)\n    print('Accuracy:',accuracy.round(4))\n    print('Precision:',precision.round(4))\n    print('Recall:',recall.round(4))\n    print('F1:',f1.round(4))\n\n    # Plot the confusion matrix\n    plt.figure(figsize=(10,8))\n    sns.heatmap(cm.T, cmap='Blues', xticklabels=list(label_mapping.keys()), yticklabels=list(label_mapping.keys()), annot=True, fmt=\"d\")\n    plt.xlabel('True labels')\n    plt.ylabel('Predicted labels')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:14.027486Z","iopub.execute_input":"2022-12-18T15:18:14.027959Z","iopub.status.idle":"2022-12-18T15:18:14.080190Z","shell.execute_reply.started":"2022-12-18T15:18:14.027893Z","shell.execute_reply":"2022-12-18T15:18:14.078685Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"#### Classifier","metadata":{}},{"cell_type":"code","source":"# we advice to choose what parameters to change and include them directly among the attributes of this function\ndef build_TS_classifier(input_shape, classes):\n    \n    input_layer = tfkl.Input(shape=input_shape)\n    \n    # Convolutional\n    x = tfkl.Conv1D(\n        filters = 256,\n        kernel_size = 3,\n        padding = 'same',\n        activation = 'relu'\n        )(input_layer)\n    \n    x = tfkl.Conv1D(\n        filters = 256,\n        kernel_size = 3,\n        padding = 'same',\n        activation = 'relu'\n        )(x)\n    \n    x = tfkl.MaxPooling1D()(x)\n\n    x = tfkl.Conv1D(\n        filters = 512,\n        kernel_size = 3,\n        padding = 'same',\n        activation = 'relu'\n        )(x)\n    \n    x = tfkl.MaxPooling1D()(x)\n\n    x = tfkl.Conv1D(\n        filters = 256,\n        kernel_size = 3,\n        padding = 'same',\n        activation = 'relu'\n        )(x)\n    \n    x = tfkl.Conv1D(\n        filters = 256,\n        kernel_size = 3,\n        padding = 'same',\n        activation = 'relu'\n        )(x)\n    \n    # LSTMs\n    x = tfkl.Bidirectional(tfkl.GRU(64, return_sequences=True))(x)\n    \n    x = tfkl.Dropout(0.2, seed=seed)(x)\n    \n    x = tfkl.Bidirectional(tfkl.GRU(32))(x)\n    \n    x = tfkl.Dropout(0.2, seed=seed)(x)\n    \n    # Classifier\n    output_layer = tfkl.Dense(classes, activation='softmax')(x)\n\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='cnn_model')\n\n    # Compile the model\n    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(3e-3), metrics='accuracy')\n\n    # Return the model\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:14.081849Z","iopub.execute_input":"2022-12-18T15:18:14.082208Z","iopub.status.idle":"2022-12-18T15:18:14.117176Z","shell.execute_reply.started":"2022-12-18T15:18:14.082173Z","shell.execute_reply":"2022-12-18T15:18:14.115956Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"cross_val = True\nfinal_train = False\n\nif cross_val:\n    best_acc = 0\n    best_model = None\n    best_scaler = None\n    best_pca = None\n    best_history =  []\n    \n    # grid search FORs go here (remember to indent the following code: SEE THEN)\n    #print(f'°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°° MODEL {i} °°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°')\n    \n    print(f'°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°° START °°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°')\n\n    acc_per_fold = []\n    fold_no = 1\n    for train, test in kfold.split(X, y_num):\n        print(f'Training for fold {fold_no} ...', end=' ')\n\n        # Intantiate a new model\n        model = build_TS_classifier(input_shape, classes)\n        \n        # Define targets\n        y_train = np.copy(y[train])\n        y_test = np.copy(y[test])\n        \n        # Apply scaling\n        X_train, X_test = scale(np.copy(X[train]), np.copy(X[test]), scaler, pca)\n\n        history = model.fit(X_train, y_train,\n                  batch_size = batch_size,\n                  epochs = epochs,\n                  validation_data = (X_test, y_test),\n                  #class_weight = class_weights,\n                  verbose = 0,\n                  callbacks = [\n                      tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=51, restore_best_weights=True),\n                      tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=tf.math.exp(-0.1), min_lr=1e-5)\n                  ]\n        ).history\n\n        # Generate generalization metrics\n        acc = np.max(history['val_accuracy']) * 100\n        print(f'score: accuracy of {acc:.3f}%')\n        acc_per_fold.append(acc)\n        if not final_train and acc > best_acc:\n            best_acc = acc\n            best_model = model\n            best_history = history\n            best_scaler = scaler\n            best_pca = pca\n\n        # Increase fold number\n        fold_no = fold_no + 1\n        print('------------------------------------------------------------------------')\n\n    print('\\nAverage scores for all folds:')\n    acc = np.mean(acc_per_fold)\n    print(f'> Accuracy: {acc:.3f}% (+- {np.std(acc_per_fold):.3f}%)')\n    if final_train and acc > best_acc:\n            best_acc = acc\n            best_model = model\n            best_history = history\n    \n    # INDENT TILL THE PREVIOUS LINE\n    print('°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°')\n              \n    # Plot results\n    best_model.summary()\n    plot_history(best_history)\n\n    # Retrain the best model on the whole dataset\n    if final_train:\n        \n        # Reinstanciate the model (if we have parameters we must pass them over)\n        best_model = build_TS_classifier(input_shape, classes)\n        \n        # Apply scaling\n        X, _ = scale(X, None, scaler, pca)\n        \n        best_model.fit(\n            x = X,\n            y = y,\n            batch_size = batch_size,\n            epochs = epochs,\n            #class_weight = class_weights,\n            callbacks = [\n                tfk.callbacks.EarlyStopping(monitor='accuracy', mode='max', patience=81, restore_best_weights=True),\n                tfk.callbacks.ReduceLROnPlateau(monitor='accuracy', mode='max', patience=10, factor=tf.math.exp(-0.1), min_lr=1e-5)\n            ]\n        )\n    \nelse:\n    \n    best_model = build_TS_classifier(input_shape, classes)\n    best_model.summary()\n    \n    # Train the model\n    best_history = best_model.fit(\n        x = X_train,\n        y = y_train,\n        batch_size = batch_size,\n        epochs = epochs,\n        validation_data = (X_test, y_test),\n        #class_weight = class_weights,\n        callbacks = [\n            tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=81, restore_best_weights=True),\n            tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=10, factor=tf.math.exp(-0.1), min_lr=1e-5)\n        ]\n    ).history\n\n    # Plot results\n    plot_history(best_history)\n    plot_cm(best_model)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:14.124669Z","iopub.execute_input":"2022-12-18T15:18:14.125771Z","iopub.status.idle":"2022-12-18T15:19:02.158372Z","shell.execute_reply.started":"2022-12-18T15:18:14.125733Z","shell.execute_reply":"2022-12-18T15:19:02.156985Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°° START °°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°°\nTraining for fold 1 ... ","output_type":"stream"},{"name":"stderr","text":"2022-12-18 15:18:14.153973: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-18 15:18:14.154440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-18 15:18:14.155345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-18 15:18:14.156168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-18 15:18:14.816893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-18 15:18:14.817727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-18 15:18:14.818396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-18 15:18:14.818985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2022-12-18 15:18:16.128171: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2022-12-18 15:18:21.230324: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"score: accuracy of 66.255%\n------------------------------------------------------------------------\nTraining for fold 2 ... ","output_type":"stream"},{"name":"stderr","text":"Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x7fc16aae18c0>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 546, in __del__\n    handle=self._handle, deleter=self._deleter)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1264, in delete_iterator\n    _ctx, \"DeleteIterator\", name, handle, deleter)\nKeyboardInterrupt: \n\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Save the scalers","metadata":{}},{"cell_type":"code","source":"# Needed to write correct preprocessing code: returns the scalers fit on the whole dataset only if \n# the \"final_train\" flag is set, otherwise returns the ones fit on the best fold\nif not final_train:\n    scaler = best_scaler\n    pca = best_pca\n    \nos.mkdir(\"scalers\")\nscaler_filename = \"scalers/scaler.save\"\njoblib.dump(scaler, scaler_filename) \npca_filename = \"scalers/pca.save\"\njoblib.dump(pca, pca_filename) \n\nshutil.make_archive('scalers', 'zip', 'scalers')","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:19:02.159758Z","iopub.status.idle":"2022-12-18T15:19:02.160602Z","shell.execute_reply.started":"2022-12-18T15:19:02.160347Z","shell.execute_reply":"2022-12-18T15:19:02.160371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Save the model","metadata":{}},{"cell_type":"code","source":"best_model.save('best_model')\n\nshutil.make_archive('best_model', 'zip', 'best_model')","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:19:02.162034Z","iopub.status.idle":"2022-12-18T15:19:02.162776Z","shell.execute_reply.started":"2022-12-18T15:19:02.162487Z","shell.execute_reply":"2022-12-18T15:19:02.162511Z"},"trusted":true},"execution_count":null,"outputs":[]}]}