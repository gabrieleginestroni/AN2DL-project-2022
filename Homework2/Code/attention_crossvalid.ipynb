{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"830302ffa9751c9d00ec7acc7b0cf1db10db4d450fa3f08a82573b165c9771b0"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import libraries","metadata":{"id":"zfehjCy896Fd"}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight, shuffle\nimport warnings\nimport logging\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)\n\nprint(tf.config.list_physical_devices())\n\nimport shutil\nfrom IPython.display import FileLink\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_wVYNVVfr6q","outputId":"812f6cdf-089b-4ef4-a5f6-7e69cdcfa205","execution":{"iopub.status.busy":"2022-12-17T17:28:31.813805Z","iopub.execute_input":"2022-12-17T17:28:31.814520Z","iopub.status.idle":"2022-12-17T17:28:31.823866Z","shell.execute_reply.started":"2022-12-17T17:28:31.814483Z","shell.execute_reply":"2022-12-17T17:28:31.822799Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"2.6.4\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tsaug","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:31.835250Z","iopub.execute_input":"2022-12-17T17:28:31.835517Z","iopub.status.idle":"2022-12-17T17:28:41.083092Z","shell.execute_reply.started":"2022-12-17T17:28:31.835493Z","shell.execute_reply":"2022-12-17T17:28:41.081910Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tsaug in /opt/conda/lib/python3.7/site-packages (0.2.1)\nRequirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.7/site-packages (from tsaug) (1.21.6)\nRequirement already satisfied: scipy>=1.1 in /opt/conda/lib/python3.7/site-packages (from tsaug) (1.7.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### Set seed for reproducibility","metadata":{"id":"lQWEHP13tQsc"}},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"id":"imBtfhUPLwB-","execution":{"iopub.status.busy":"2022-12-17T17:28:41.087330Z","iopub.execute_input":"2022-12-17T17:28:41.087666Z","iopub.status.idle":"2022-12-17T17:28:41.139430Z","shell.execute_reply.started":"2022-12-17T17:28:41.087636Z","shell.execute_reply":"2022-12-17T17:28:41.136772Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"Hyper parameters for augmentation, splines interpolation and scaling","metadata":{}},{"cell_type":"code","source":"scaling = True # applies standard scaling to the data\napply_oversampling = False \ninterpolation_multiplier = 3 # resolution multiplier\naugment_std = 0.04# introduces noise to the oversampled data\nuse_cross_valid = True","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.140946Z","iopub.execute_input":"2022-12-17T17:28:41.141398Z","iopub.status.idle":"2022-12-17T17:28:41.149956Z","shell.execute_reply.started":"2022-12-17T17:28:41.141359Z","shell.execute_reply":"2022-12-17T17:28:41.148979Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":" ## Load the training dataset","metadata":{"id":"GMysAd_I-lED"}},{"cell_type":"code","source":"path = \"/kaggle/input/training/\"\n# Load the .npy file\nX = np.load(path + \"x_train.npy\")\ny = np.load(path + \"y_train.npy\")\n\n# Convert to float32 for less precision and better performance\nX = X.astype(np.float64)\ny = y.astype(np.int32)\n\n# shuffle X, y\nX, y = shuffle(X, y, random_state=seed)\n\nprint(X.shape, X.dtype, sep=\", \")   \nprint(y.shape, y.dtype, sep=\", \") ","metadata":{"id":"C0m6Gn4fkm9S","execution":{"iopub.status.busy":"2022-12-17T17:28:41.153022Z","iopub.execute_input":"2022-12-17T17:28:41.153408Z","iopub.status.idle":"2022-12-17T17:28:41.176555Z","shell.execute_reply.started":"2022-12-17T17:28:41.153371Z","shell.execute_reply":"2022-12-17T17:28:41.175553Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"(2429, 36, 6), float64\n(2429,), int32\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Training - Validation Split","metadata":{}},{"cell_type":"code","source":"if not use_cross_valid:\n    # Split the data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,shuffle=True, random_state=seed, stratify=y)\n    print(\"training set : \", X_train.shape)\n    print(\"test set: \", X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.177876Z","iopub.execute_input":"2022-12-17T17:28:41.179339Z","iopub.status.idle":"2022-12-17T17:28:41.184831Z","shell.execute_reply.started":"2022-12-17T17:28:41.179304Z","shell.execute_reply":"2022-12-17T17:28:41.183856Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"Plotting the classes distributions","metadata":{}},{"cell_type":"code","source":"# Map classes STRINGS to integers\nlabel_mapping = {\n    'Wish': 0,\n    'Another': 1,\n    'Comfortably': 2,\n    'Money': 3,\n    'Breathe': 4,\n    'Time': 5,\n    'Brain': 6,\n    'Echoes': 7,\n    'Wearing': 8,\n    'Sorrow': 9,\n    'Hey': 10,\n    'Shine': 11,  \n}\n\n#vertical bar plot of the classes distribution in y\nplt.title('Classes distribution')\nplt.bar(label_mapping.keys(), np.bincount(y), color = matplotlib.colormaps['Set2'].colors)\nplt.xticks(rotation=90)\nplt.ylabel('Count')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.186305Z","iopub.execute_input":"2022-12-17T17:28:41.186947Z","iopub.status.idle":"2022-12-17T17:28:41.415017Z","shell.execute_reply.started":"2022-12-17T17:28:41.186910Z","shell.execute_reply":"2022-12-17T17:28:41.414006Z"},"trusted":true},"execution_count":57,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"Class weights computation","metadata":{}},{"cell_type":"code","source":"# Compute the class weights in order to balance loss during training\nlabels = np.unique(np.fromiter([t for t in y], np.int32))\nclass_weights = dict(enumerate(class_weight.compute_class_weight('balanced', classes=labels, y=y)))\n\n# plot class weights with respect to the labels\nplt.title('Class weights')\nplt.bar(label_mapping.keys(), class_weights.values(), color = matplotlib.colormaps['Set2'].colors)\nplt.xticks(rotation=90)\nplt.ylabel('Weight')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.418135Z","iopub.execute_input":"2022-12-17T17:28:41.418399Z","iopub.status.idle":"2022-12-17T17:28:41.631034Z","shell.execute_reply.started":"2022-12-17T17:28:41.418374Z","shell.execute_reply":"2022-12-17T17:28:41.630022Z"},"trusted":true},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"## Data preprocessing with cubic interpolation between data points for increasing resolution","metadata":{}},{"cell_type":"markdown","source":"Before the cubic spline interpolation ","metadata":{}},{"cell_type":"code","source":"def spline_augment_print(X_train,y_train,interpolation_multiplier = 3,augment_std = 0.02):\n    # plot the sequence of points in a randomly drawn sample from X\n    sample = random.randint(0, X_train.shape[0])\n\n    # create a figure with 6 subplots, one plot per each feature\n    fig, axs = plt.subplots(6, 1, figsize=(9, 13))\n    fig.suptitle('Sample ' + str(sample))\n    for i in range(6):\n        axs[i].set_title('Feature ' + str(i))\n        # add a dot at each point in the sequence\n        axs[i].plot(X_train[sample, :, i], 'o-', color='blue', markersize=4)\n\n    plt.show()\n    \n    from scipy import interpolate\n\n    # triple the number of points in the sequence to increase the resolution by a factor of 3\n    x_lin = np.linspace(0, 35, 36 * interpolation_multiplier)\n\n    # new augmented dataset\n    X_spline = np.zeros((X_train.shape[0], x_lin.size, 6))\n    print(X_spline.shape)\n\n    for i in np.arange(X_train[:, 0, 0].size): # for each sample\n        for j in np.arange(6): # for each feature\n            # add a cubic spline interpolation between the data points of X[sample, :, 0]\n            interpolation = interpolate.interp1d(np.arange(0, 36), X_train[i, :, j], kind='cubic', fill_value=\"extrapolate\")\n            X_spline[i, :, j] = interpolation(x_lin)\n    # create a figure with 6 subplots, one plot per each feature\n    fig, axs = plt.subplots(6, 1, figsize=(9, 14))\n    fig.suptitle('Sample ' + str(sample))\n    for i in range(6):\n        axs[i].set_title('Feature ' + str(i))\n        # plots the given sequence of points without interpolation\n        axs[i].plot(np.arange(0, 36), X_train[sample, :, i], 'o-', color='blue', markersize=4)\n\n        # plots the new set of points with cubic spline interpolation\n        axs[i].plot(x_lin, X_spline[sample, :, i], \"o-\", color='red', markersize = 3, alpha = 0.7)\n    plt.show()\n    # create a new augmented dataset with the new samples that is as big as the original training dataset\n    X_augmented = np.empty((0, X_train.shape[1], X_train.shape[2]), dtype=np.float32)\n    y_augmented = np.empty((0,), dtype=np.int32)\n\n    print(\"interpolation_multiplier = \", interpolation_multiplier)\n\n    # for each sample in the training dataset\n    for i in range(y_train.shape[0]):\n\n        # copy the original sample in the augmented dataset every 3 points from X_spline[i, k, :]\n        for j in range(interpolation_multiplier):\n            X_augmented = np.append(X_augmented, np.expand_dims(X_spline[i, j::interpolation_multiplier, :], axis=0), axis=0)\n            y_augmented = np.append(y_augmented, np.expand_dims(y_train[i], axis=0), axis=0)\n\n            # for each sample, add a random gaussian noise to each feature\n\n            for k in range(X_augmented.shape[2]):\n                mins = np.min(X_augmented[-1, :, k], axis=0)\n                maxs = np.max(X_augmented[-1, :, k], axis=0)\n\n                values = np.random.normal(0, augment_std * (maxs - mins), X_augmented.shape[1])\n                X_augmented[-1, :, k] = np.add(X_augmented[-1, :, k], values)\n\n    print(\"new augmented dataset size \", X_augmented.shape, y_augmented.shape, sep=\", \")\n\n    # shuffle the data\n    X_augmented, y_augmented = shuffle(X_augmented, y_augmented, random_state=seed)\n    \n    return X_augmented, y_augmented","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.632582Z","iopub.execute_input":"2022-12-17T17:28:41.633157Z","iopub.status.idle":"2022-12-17T17:28:41.649977Z","shell.execute_reply.started":"2022-12-17T17:28:41.633119Z","shell.execute_reply":"2022-12-17T17:28:41.649074Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"#redefining the function not to print (to be used in crossvalidation)\ndef spline_augment_no_print(X_train,y_train,interpolation_multiplier = 3,augment_std = 0.02):\n\n    from scipy import interpolate\n\n    # triple the number of points in the sequence to increase the resolution by a factor of 3\n    x_lin = np.linspace(0, 35, 36 * interpolation_multiplier)\n\n    # new augmented dataset\n    X_spline = np.zeros((X_train.shape[0], x_lin.size, 6))\n\n\n    for i in np.arange(X_train[:, 0, 0].size): # for each sample\n        for j in np.arange(6): # for each feature\n            # add a cubic spline interpolation between the data points of X[sample, :, 0]\n            interpolation = interpolate.interp1d(np.arange(0, 36), X_train[i, :, j], kind='cubic', fill_value=\"extrapolate\")\n            X_spline[i, :, j] = interpolation(x_lin)\n    \n    # create a new augmented dataset with the new samples that is as big as the original training dataset\n    X_augmented = np.empty((0, X_train.shape[1], X_train.shape[2]), dtype=np.float32)\n    y_augmented = np.empty((0,), dtype=np.int32)\n\n    # for each sample in the training dataset\n    for i in range(y_train.shape[0]):\n\n        # copy the original sample in the augmented dataset every 3 points from X_spline[i, k, :]\n        for j in range(interpolation_multiplier):\n            X_augmented = np.append(X_augmented, np.expand_dims(X_spline[i, j::interpolation_multiplier, :], axis=0), axis=0)\n            y_augmented = np.append(y_augmented, np.expand_dims(y_train[i], axis=0), axis=0)\n\n            # for each sample, add a random gaussian noise to each feature\n\n            for k in range(X_augmented.shape[2]):\n                mins = np.min(X_augmented[-1, :, k], axis=0)\n                maxs = np.max(X_augmented[-1, :, k], axis=0)\n\n                values = np.random.normal(0, augment_std * (maxs - mins), X_augmented.shape[1])\n                X_augmented[-1, :, k] = np.add(X_augmented[-1, :, k], values)\n\n    # shuffle the data\n    X_augmented, y_augmented = shuffle(X_augmented, y_augmented, random_state=seed)\n    \n    return X_augmented, y_augmented","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.651450Z","iopub.execute_input":"2022-12-17T17:28:41.651866Z","iopub.status.idle":"2022-12-17T17:28:41.667581Z","shell.execute_reply.started":"2022-12-17T17:28:41.651830Z","shell.execute_reply":"2022-12-17T17:28:41.666668Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"## Application of Standard Scaler to the dataset","metadata":{}},{"cell_type":"code","source":"if not use_cross_valid:\n    #X_train = np.delete(X_train, 3, axis=2)\n    #X_test = np.delete(X_test, 3, axis=2)\n    \n    features_num = X_train.shape[2]\n    print(\"features: \", features_num)\n\n    #(optional) apply spline augmentation\n    #X_train,y_train = spline_augment_print(X_train,y_train,interpolation_multiplier = 3,augment_std = 0.02)\n    # if the standard scaling is requested, computes it on the training set and prints its values\n    if (scaling):\n        scaler_robust = RobustScaler()\n        scaler_std = StandardScaler()\n        scaler_0 = MinMaxScaler(feature_range=(0,1))\n        scaler_1 = MinMaxScaler(feature_range=(-1,1))\n\n        num_instances, num_time_steps, num_features = X_train.shape\n        X_train = np.reshape(X_train, newshape=(-1, num_features))\n        X_train = scaler_robust.fit_transform(X_train)\n        X_train = scaler_1.fit_transform(X_train)\n        X_train = scaler_std.fit_transform(X_train)\n\n        X_train = np.reshape(X_train, newshape=(num_instances, num_time_steps, num_features))\n\n        num_instances, num_time_steps, num_features = X_test.shape\n        X_test = np.reshape(X_test, newshape=(-1, num_features))\n        X_test = scaler_robust.transform(X_test)\n        X_test = scaler_1.transform(X_test)\n        X_test = scaler_std.transform(X_test)\n\n        X_test = np.reshape(X_test, newshape=(num_instances, num_time_steps, num_features))\n        print(\"std_scaler: \"+str(scaler_std.__dict__))\n        print(\"min_max_scaler_1: \"+str(scaler_1.__dict__))\n        print(\"min_max_scaler_0: \"+str(scaler_0.__dict__))\n","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.671874Z","iopub.execute_input":"2022-12-17T17:28:41.672181Z","iopub.status.idle":"2022-12-17T17:28:41.682581Z","shell.execute_reply.started":"2022-12-17T17:28:41.672155Z","shell.execute_reply":"2022-12-17T17:28:41.681624Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"Categorical labels for the training and test data","metadata":{}},{"cell_type":"code","source":"if not use_cross_valid:   \n    # Convert the sparse labels to categorical values\n    y_train = tfk.utils.to_categorical(y_train)\n    y_test = tfk.utils.to_categorical(y_test)\n    print(X_train.shape, y_train.shape, sep=\", \")\n    print(X_test.shape, y_test.shape, sep=\", \")","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.683875Z","iopub.execute_input":"2022-12-17T17:28:41.684606Z","iopub.status.idle":"2022-12-17T17:28:41.696012Z","shell.execute_reply.started":"2022-12-17T17:28:41.684569Z","shell.execute_reply":"2022-12-17T17:28:41.695084Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"## Build the models","metadata":{}},{"cell_type":"markdown","source":"Hyperparameters","metadata":{}},{"cell_type":"code","source":"if not use_cross_valid:  \n    input_shape = X_train.shape[1:]\n    print(\"input shape: \", input_shape)\n    classes = y_train.shape[-1]\nbatch_size = 512\nepochs = 800\n","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.697265Z","iopub.execute_input":"2022-12-17T17:28:41.697693Z","iopub.status.idle":"2022-12-17T17:28:41.705807Z","shell.execute_reply.started":"2022-12-17T17:28:41.697659Z","shell.execute_reply":"2022-12-17T17:28:41.704941Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"Plot history of the training and the learning rate schedule","metadata":{}},{"cell_type":"code","source":"def plot_history(history):\n\tbest_epoch = np.argmax(history['val_accuracy'])\n\tplt.figure(figsize=(17,4))\n\tplt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n\tplt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n\tplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n\tplt.title('Categorical Crossentropy')\n\tplt.legend()\n\tplt.grid(alpha=.3)\n\tplt.show()\n\n\tplt.figure(figsize=(17,4))\n\tplt.plot(history['accuracy'], label='Training accuracy', alpha=.8, color='#ff7f0e')\n\tplt.plot(history['val_accuracy'], label='Validation accuracy', alpha=.9, color='#5a9aa5')\n\tplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n\tplt.title('Accuracy')\n\tplt.legend()\n\tplt.grid(alpha=.3)\n\tplt.show()\n\n\tplt.figure(figsize=(17,4))\n\tplt.title('Learning Rate Schedule')\n\tplt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n\tplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n\tplt.legend()\n\tplt.grid(alpha=.3)\n\tplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.706908Z","iopub.execute_input":"2022-12-17T17:28:41.707202Z","iopub.status.idle":"2022-12-17T17:28:41.719476Z","shell.execute_reply.started":"2022-12-17T17:28:41.707177Z","shell.execute_reply":"2022-12-17T17:28:41.718425Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"Plot confusion matrix, F1 scores and displays model accuracy","metadata":{}},{"cell_type":"code","source":"def plot_statistics(predictions):\t\n\t# Compute the confusion matrix\n\tcm = confusion_matrix(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1))\n\n\t# Compute the classification metrics\n\taccuracy = accuracy_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1))\n\tprecision = precision_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n\trecall = recall_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n\tf1 = f1_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n\tprint('Accuracy:',accuracy.round(4))\n\tprint('Precision:',precision.round(4))\n\tprint('Recall:',recall.round(4))\n\tprint('F1:',f1.round(4))\n\n\t# Plot the confusion matrix\n\tplt.figure(figsize=(7, 6))\n\tplt.title('Confusion matrix')\n\tsns.heatmap(cm.T, cmap='Blues', xticklabels=list(label_mapping.keys()), yticklabels=list(label_mapping.keys()), annot=True, fmt=\"d\")\n\tplt.xlabel('True labels')\n\tplt.ylabel('Predicted labels')\n\tplt.show()\n\n\t# horizontal bar plot of the f1 scores for each class\n\tplt.figure(figsize=(6,4))\n\tplt.grid(alpha=.3)\n\tplt.barh(y=list(label_mapping.keys()), width=f1_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average=None))\n\tplt.title('F1 scores')\n\tplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.721040Z","iopub.execute_input":"2022-12-17T17:28:41.721471Z","iopub.status.idle":"2022-12-17T17:28:41.734372Z","shell.execute_reply.started":"2022-12-17T17:28:41.721383Z","shell.execute_reply":"2022-12-17T17:28:41.733394Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n\nclass AttentionLayer(tfkl.Layer):\n    def _init_(self, **kwargs):\n        super(AttentionLayer, self)._init_(**kwargs)\n\n    def build(self, input_shape):\n        # Create a trainable weight variable for this layer.\n        self.W = self.add_weight(name='attention_weight', \n                                 shape=(input_shape[-1], 1),\n                                 initializer='uniform',\n                                 trainable=True)\n        super(AttentionLayer, self).build(input_shape)\n\n    def call(self, inputs, mask=None):\n        # inputs: (batch_size, time_steps, input_dim)\n        # mask: (batch_size, time_steps)\n\n        # Apply a dot product between the input and the trainable weight to\n        # get a score for each time step.\n        score = K.dot(inputs, self.W)\n        score = K.squeeze(score, axis=-1)\n        # Apply a softmax activation to the score to compute the attention\n        # weights for each time step.\n        attention_weights = K.softmax(score)\n        # Multiply the attention weights by the input to compute the\n        # weighted sum of the input.\n        weighted_sum = K.sum(K.expand_dims(attention_weights, axis=-1) * inputs, axis=1)\n        # Return the attention-weighted sum of the input.\n        return weighted_sum\n\n    def compute_output_shape(self, input_shape):\n        # The output shape is the same as the input shape, except the input\n        # dimension is reduced by one.\n        return (input_shape[0], input_shape[-1])","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.737571Z","iopub.execute_input":"2022-12-17T17:28:41.737922Z","iopub.status.idle":"2022-12-17T17:28:41.748948Z","shell.execute_reply.started":"2022-12-17T17:28:41.737896Z","shell.execute_reply":"2022-12-17T17:28:41.748008Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"#### Only convolutional and dense layers","metadata":{}},{"cell_type":"code","source":"\n\ndef build_classifier(input_shape, classes):\n    # Build the neural network layer by layer\n    input_layer = tfkl.Input(shape=input_shape, name='Input')\n\n    \n    #head1\n    y = tfkl.Conv1D(\n        filters = 256,\n        kernel_size = 3,\n        padding = 'same',\n        activation = 'relu',\n        kernel_initializer = tfk.initializers.HeUniform(seed),\n        name = 'conv1y')(input_layer)\n\n    #y = tfkl.Dropout(0.15, seed=seed)(y)\n\n    #y = tfkl.UpSampling1D(size=2)(y)\n\n    #y = tfkl.MaxPooling1D()(y)\n    \n    y = tfkl.Dropout(0.1, seed=seed)(y)\n\n    y = tfkl.Conv1D(\n        filters = 256,\n        kernel_size = 3,\n        padding = 'same',\n        activation = 'relu',\n        kernel_initializer = tfk.initializers.HeUniform(seed),\n        name = 'conv2y')(y)\n    \n    y = tfkl.Dropout(0.1, seed=seed)(y)\n    #y = tfkl.MaxPooling1D()(y)\n    \n    y = tfkl.Conv1D(\n        filters = 128,\n        kernel_size = 3,\n        padding = 'same',\n        activation = 'relu',\n        kernel_initializer = tfk.initializers.HeUniform(seed),\n        name = 'conv3y')(y)\n\n    #y = tfkl.MaxPooling1D()(y)\n\n    y = tfkl.Dropout(0.1, seed=seed)(y)\n\n\n    #y = tfkl.Dropout(0.15, seed=seed)(y)\n\n    #y = tfkl.GlobalAveragePooling1D(name='gapy')(y)\n    \n    #y = tfkl.Dropout(0.3, seed=seed)(y)\n\n    #head4-LSTM\n    \n    r = tfkl.Bidirectional(tfkl.GRU(60, return_sequences=True, name='lstm1'))(y)\n    r = tfkl.Dropout(0.3, seed=seed)(r)\n    r = tfkl.Bidirectional(tfkl.GRU(60, return_sequences=True, name='lstm2'))(r)\n    r = tfkl.Dropout(0.3, seed=seed)(r)\n\n    #x = tfkl.Bidirectional(tfkl.GRU(16, return_sequences=True, name='lstm3'))(y)\n    #x = tfkl.Dropout(0.4, seed=seed)(x)\n    #x = tfkl.Bidirectional(tfkl.GRU(16, return_sequences=False, name='lstm2'))(x)\n    #x = tfkl.Dropout(0.4, seed=seed)(x)\n\n    #x = tfkl.GlobalAveragePooling1D()(r)\n    #x = tfkl.Dropout(0.3, seed=seed)(x)\n    x = AttentionLayer()(r)\n\n    #x = tfkl.Dropout(0.3, seed=seed)(x)\n    output_layer = tfkl.Dense(classes, activation='softmax',kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model1')\n\n    # Compile the model\n    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n\n    # Return the model\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.752052Z","iopub.execute_input":"2022-12-17T17:28:41.752579Z","iopub.status.idle":"2022-12-17T17:28:41.766641Z","shell.execute_reply.started":"2022-12-17T17:28:41.752551Z","shell.execute_reply":"2022-12-17T17:28:41.765663Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"if not use_cross_valid:  \n    model = build_classifier(input_shape,classes)\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.768579Z","iopub.execute_input":"2022-12-17T17:28:41.768848Z","iopub.status.idle":"2022-12-17T17:28:41.781863Z","shell.execute_reply.started":"2022-12-17T17:28:41.768825Z","shell.execute_reply":"2022-12-17T17:28:41.780865Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"if not use_cross_valid:\n    \n    # Train the model\n    history = model.fit(\n        x = X_train,\n        y = y_train,\n        batch_size = batch_size,\n        epochs = epochs,\n        validation_data = (X_test, y_test),\n        #class_weight = class_weights,\n        callbacks = [\n            tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=100, restore_best_weights=True),\n            tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=7, factor=0.6, min_lr=5e-5)\n        ]\n    ).history","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.784984Z","iopub.execute_input":"2022-12-17T17:28:41.785354Z","iopub.status.idle":"2022-12-17T17:28:41.792569Z","shell.execute_reply.started":"2022-12-17T17:28:41.785313Z","shell.execute_reply":"2022-12-17T17:28:41.791489Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"Convolutional model evaluation","metadata":{}},{"cell_type":"code","source":"if not use_cross_valid:\n    plot_history(history)\n\n    # Predict the test set with the LSTM\n    predictions = model.predict(X_test)\n\n    plot_statistics(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.794238Z","iopub.execute_input":"2022-12-17T17:28:41.794643Z","iopub.status.idle":"2022-12-17T17:28:41.807184Z","shell.execute_reply.started":"2022-12-17T17:28:41.794611Z","shell.execute_reply":"2022-12-17T17:28:41.806156Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"Save model with the validation accuracy in the name","metadata":{}},{"cell_type":"code","source":"if not use_cross_valid:\n    accuracy = accuracy_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1))\n    if (accuracy > 0.75):\n        model_name = \"model_GRU_\" + str(accuracy.round(6))\n        model.save(model_name)\n\n        \n        FileLink(r\"\" + model_name + \".zip\")\n        import joblib\n        scaler_std_filename =model_name+ \"/scaler_std.save\"\n        joblib.dump(scaler_std, scaler_std_filename) \n        scaler_1_filename =model_name+ \"/scaler_1.save\"\n        joblib.dump(scaler_1, scaler_1_filename) \n        scaler_robust_filename =model_name+ \"/scaler_robust.save\"\n        joblib.dump(scaler_robust, scaler_robust_filename) \n\n        shutil.make_archive(model_name, 'zip', model_name)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.808631Z","iopub.execute_input":"2022-12-17T17:28:41.808926Z","iopub.status.idle":"2022-12-17T17:28:41.819038Z","shell.execute_reply.started":"2022-12-17T17:28:41.808886Z","shell.execute_reply":"2022-12-17T17:28:41.818120Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cross Validation","metadata":{}},{"cell_type":"code","source":"def scale_feature_wise(X_train, X_test):  #apply rescaling to each feature\n    scaler_robust = RobustScaler()\n    scaler_std = StandardScaler()\n    scaler_0 = MinMaxScaler(feature_range=(0,1))\n    scaler_1 = MinMaxScaler(feature_range=(-1,1))\n\n    num_instances, num_time_steps, num_features = X_train.shape\n    X_train = np.reshape(X_train, newshape=(-1, num_features))\n    X_train = scaler_robust.fit_transform(X_train)\n    X_train = scaler_1.fit_transform(X_train)\n    X_train = scaler_std.fit_transform(X_train)\n\n    X_train = np.reshape(X_train, newshape=(num_instances, num_time_steps, num_features))\n\n        \n    \n    if X_test is not None:\n        num_instances, num_time_steps, num_features = X_test.shape\n        X_test = np.reshape(X_test, newshape=(-1, num_features))\n        X_test = scaler_robust.transform(X_test)\n        X_test = scaler_1.transform(X_test)\n        X_test = scaler_std.transform(X_test)\n\n        X_test = np.reshape(X_test, newshape=(num_instances, num_time_steps, num_features))\n        return X_train, X_test\n    \n    return X_train\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.820407Z","iopub.execute_input":"2022-12-17T17:28:41.820907Z","iopub.status.idle":"2022-12-17T17:28:41.830341Z","shell.execute_reply.started":"2022-12-17T17:28:41.820872Z","shell.execute_reply":"2022-12-17T17:28:41.829500Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"def scale_ts_feature_wise(X_train, X_test):  #apply rescaling to each (timestamp,feature) pair\n    scaler_robust = RobustScaler()\n    scaler_std = StandardScaler()\n    scaler_0 = MinMaxScaler(feature_range=(0,1))\n    scaler_1 = MinMaxScaler(feature_range=(-1,1))\n\n    num_instances, num_time_steps, num_features = X_train.shape\n    X_train = np.reshape(X_train, newshape=(-1, num_features * num_time_steps))\n    X_train = scaler_robust.fit_transform(X_train)\n    X_train = scaler_1.fit_transform(X_train)\n    X_train = scaler_std.fit_transform(X_train)\n\n    X_train = np.reshape(X_train, newshape=(num_instances, num_time_steps, num_features))\n\n        \n    \n    if X_test is not None:\n        num_instances, num_time_steps, num_features = X_test.shape\n        X_test = np.reshape(X_test, newshape=(-1, num_features * num_time_steps))\n        X_test = scaler_robust.transform(X_test)\n        X_test = scaler_1.transform(X_test)\n        X_test = scaler_std.transform(X_test)\n\n        X_test = np.reshape(X_test, newshape=(num_instances, num_time_steps, num_features))\n        return X_train, X_test\n    \n    return X_train","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.831743Z","iopub.execute_input":"2022-12-17T17:28:41.832551Z","iopub.status.idle":"2022-12-17T17:28:41.844507Z","shell.execute_reply.started":"2022-12-17T17:28:41.832513Z","shell.execute_reply":"2022-12-17T17:28:41.843493Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.utils import class_weight\n# Define the K-fold Cross Validator\nnum_folds = 7\nkfold = StratifiedKFold(n_splits=num_folds, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:28:41.845830Z","iopub.execute_input":"2022-12-17T17:28:41.846699Z","iopub.status.idle":"2022-12-17T17:28:41.858388Z","shell.execute_reply.started":"2022-12-17T17:28:41.846663Z","shell.execute_reply":"2022-12-17T17:28:41.857402Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# testing timeseries augmentation with crossvalidation\n\nif use_cross_valid:\n    best_acc = 0\n    best_model = None\n    best_history =  []\n    \n    # grid search FORs go here (remember to indent the following code: SEE THEN)\n    #print(f' MODEL {i} ')\n    \n    print(f' START ')\n\n    acc_per_fold = []\n    loss_per_fold = []\n    fold_no = 1\n    for train, test in kfold.split(X, y):\n        print(f'Training for fold {fold_no} ...', end=' ')\n        \n        X_train = np.copy(X[train])\n        y_train = np.copy(y[train])\n        X_test = np.copy(X[test])\n        y_test = np.copy(y[test])\n        \n        #drop some feature\n        #X_train = np.delete(X_train, 5, axis=2)\n        #X_test = np.delete(X_test, 5, axis=2)\n        \n        #test splines augmentation: creating new synthetic samples\n        #by increasing the resolution of original series and adding gaussian noise\n        #note that training will be much slower since augmentation is computed by CPU\n        #and interpolation_multiplier linearly increases training set size\n        \n        #X_train,y_train = spline_augment_no_print(X_train,y_train,interpolation_multiplier = 2,augment_std = 0.05)\n        \n        y_train = tfk.utils.to_categorical(y_train)\n        y_test = tfk.utils.to_categorical(y_test)\n        classes = y_train.shape[-1]\n        input_shape = X_train.shape[1:]\n        \n        # Apply scaling (use only one of the following two)\n        #X_train,X_test = scale_ts_feature_wise(X_train, X_test)\n        X_train,X_test = scale_feature_wise(X_train, X_test)\n\n         # Intantiate a new model\n            \n        model = build_classifier(input_shape, classes)\n        \n        history = model.fit(X_train, y_train,\n                  batch_size = batch_size,\n                  epochs = epochs,\n                  validation_data = (X_test, y_test),\n                  #class_weight = class_weights,\n                  verbose=0,\n                  callbacks = [\n                      tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=100, restore_best_weights=True),\n                      tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=7, factor=0.6, min_lr=5e-5)\n                  ]\n        ).history\n        \n        # Generate generalization metrics\n        acc = np.max(history['val_accuracy']) * 100\n        print(f'score: accuracy of {acc}%')\n        acc_per_fold.append(acc)\n\n        # Increase fold number\n        fold_no = fold_no + 1\n        if fold_no <= num_folds + 1:\n            print('------------------------------------------------------------------------')\n\n    print('\\nAverage scores for all folds:')\n    acc = np.mean(acc_per_fold)\n    print(f'> Accuracy: {acc} (+- {np.std(acc_per_fold)})')\n    print(f'> Loss: {np.mean(loss_per_fold)}')\n    if acc > best_acc:\n        best_acc = acc\n        best_model = model\n        best_history = history\n    \n    # INDENT TILL THE PREVIOUS LINE\n    print('')\n              \n    # Plot results\n    best_model.summary()\n    plot_history(best_history)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-17T17:34:02.403836Z","iopub.execute_input":"2022-12-17T17:34:02.404230Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":" START \nTraining for fold 1 ... ","output_type":"stream"}]},{"cell_type":"code","source":"final_train = False\nif use_cross_valid and final_train:\n        # RETRAIN THE BEST MODEL ON THE WHOLE DATASET\n        if final_train:\n    \n            # Apply scaling\n            X = scale(X, None)\n\n            best_model_history = best_model.fit(\n                x = X,\n                y = y,\n                batch_size = batch_size,\n                epochs = epochs,\n                #class_weight = class_weights,\n                callbacks = [\n                    tfk.callbacks.EarlyStopping(monitor='accuracy', mode='max', patience=81, restore_best_weights=True),\n                    tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=tf.math.exp(-0.1), min_lr=2e-5)\n                ]\n            ).history\n            \n\n            # Plot results\n            plot_history(best_model_history)\n            plot_cm(best_model)\n            \n            model_name = \"model_final_GRU_\"\n            best_model.save(model_name)\n\n\n            FileLink(r\"\" + model_name + \".zip\")\n            import joblib\n            scaler_std_filename =model_name+ \"/scaler_std.save\"\n            joblib.dump(scaler_std, scaler_std_filename) \n            scaler_1_filename =model_name+ \"/scaler_1.save\"\n            joblib.dump(scaler_1, scaler_1_filename) \n            scaler_robust_filename =model_name+ \"/scaler_robust.save\"\n            joblib.dump(scaler_robust, scaler_robust_filename) \n\n            shutil.make_archive(model_name, 'zip', model_name)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}