{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Code for competition","metadata":{}},{"cell_type":"code","source":"!apt -y install --allow-change-held-packages libcudnn8=8.6.0.163-1+cuda11.8\n\n!pip uninstall -y tensorflow \n#!pip uninstall -y tensorflow-transform\n#!pip uninstall -y tensorflow-io\n#!pip install tensorflow-transform\n!pip install tensorflow\n\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport os\nimport shutil\nfrom collections import Counter\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils import class_weight\nfrom PIL import Image\nimport re\nimport time\nfrom IPython.display import FileLink\n\n!nvidia-smi\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)\nprint(tf.config.list_physical_devices())\n\n# Enable experimental feature of memory occupation growth control \nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\nfor dev in physical_devices:\n    tf.config.experimental.set_memory_growth(dev, True)\n    \n# Enable mixed precision\nmixed_precision.set_global_policy('mixed_float16')\n\n# Enable distributed training\nstrategy = tf.distribute.MirroredStrategy()\n\n# Random seed for reproducibility\nseed = 42\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:55:56.540703Z","iopub.execute_input":"2022-11-17T21:55:56.541125Z","iopub.status.idle":"2022-11-17T21:59:09.339723Z","shell.execute_reply.started":"2022-11-17T21:55:56.541041Z","shell.execute_reply":"2022-11-17T21:59:09.338584Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  libcudnn8-dev\nThe following held packages will be changed:\n  libcudnn8\nThe following packages will be upgraded:\n  libcudnn8 libcudnn8-dev\n2 upgraded, 0 newly installed, 0 to remove and 91 not upgraded.\nNeed to get 883 MB of archives.\nAfter this operation, 1429 MB disk space will be freed.\nGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libcudnn8-dev 8.6.0.163-1+cuda11.8 [437 MB]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libcudnn8 8.6.0.163-1+cuda11.8 [446 MB]\nFetched 883 MB in 12s (73.3 MB/s)                                              \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n\n(Reading database ... 108827 files and directories currently installed.)\nPreparing to unpack .../libcudnn8-dev_8.6.0.163-1+cuda11.8_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking libcudnn8-dev (8.6.0.163-1+cuda11.8) over (8.0.5.39-1+cuda11.0) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Preparing to unpack .../libcudnn8_8.6.0.163-1+cuda11.8_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking libcudnn8 (8.6.0.163-1+cuda11.8) over (8.0.5.39-1+cuda11.0) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Setting up libcudnn8 (8.6.0.163-1+cuda11.8) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up libcudnn8-dev (8.6.0.163-1+cuda11.8) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v8.h to provide /usr/include/cudnn.h (libcudnn) in auto mode\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JFound existing installation: tensorflow 2.6.4\nUninstalling tensorflow-2.6.4:\n  Successfully uninstalled tensorflow-2.6.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting tensorflow\n  Downloading tensorflow-2.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.0)\nCollecting tensorflow-io-gcs-filesystem>=0.23.1\n  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.43.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow) (59.8.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.2)\nCollecting keras<2.11,>=2.10.0\n  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (4.1.1)\nRequirement already satisfied: tensorboard<2.11,>=2.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.1)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.0)\nCollecting libclang>=13.0.0\n  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting absl-py>=1.0.0\n  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow) (21.3)\nCollecting tensorflow-estimator<2.11,>=2.10.0\n  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.1)\nCollecting flatbuffers>=2.0\n  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\nRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.19.4)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.21.6)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.7)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.35.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow) (3.0.9)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.8)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.13.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.0)\nInstalling collected packages: libclang, keras, flatbuffers, tensorflow-io-gcs-filesystem, tensorflow-estimator, absl-py, tensorflow\n  Attempting uninstall: keras\n    Found existing installation: keras 2.6.0\n    Uninstalling keras-2.6.0:\n      Successfully uninstalled keras-2.6.0\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 1.12\n    Uninstalling flatbuffers-1.12:\n      Successfully uninstalled flatbuffers-1.12\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Uninstalling tensorflow-estimator-2.6.0:\n      Successfully uninstalled tensorflow-estimator-2.6.0\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 0.15.0\n    Uninstalling absl-py-0.15.0:\n      Successfully uninstalled absl-py-0.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.10.1 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.10.1 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, but you have tensorflow-io-gcs-filesystem 0.27.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed absl-py-1.3.0 flatbuffers-22.10.26 keras-2.10.0 libclang-14.0.6 tensorflow-2.10.1 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2022-11-17 21:59:00.818664: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-17 21:59:01.002595: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2022-11-17 21:59:02.059397: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-17 21:59:02.059670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-17 21:59:02.059687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"},{"name":"stdout","text":"Thu Nov 17 21:59:06 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n2.10.1\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n","output_type":"stream"},{"name":"stderr","text":"2022-11-17 21:59:07.087413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.088428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.220900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.221838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.222693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.223587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.227113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.228357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.231359: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-17 21:59:07.539407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.540464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.541306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.542088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.542867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:07.543730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:09.247476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:09.248362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:09.249214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:09.250197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:09.251005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:09.251726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13737 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-11-17 21:59:09.252855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-17 21:59:09.253816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13737 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Metadata","metadata":{}},{"cell_type":"code","source":"classes = [\"Species1\", \"Species2\", \"Species3\", \"Species4\", \"Species5\", \"Species6\", \"Species7\", \"Species8\"]\ninput_shape = (96, 96, 3)\ninput_size = input_shape[:-1]\ninflation_coeff = 1.5\n\nbatch_size = 128 * strategy.num_replicas_in_sync\nepochs = 400\n\nprint(batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:09.342595Z","iopub.execute_input":"2022-11-17T21:59:09.343420Z","iopub.status.idle":"2022-11-17T21:59:09.351306Z","shell.execute_reply.started":"2022-11-17T21:59:09.343377Z","shell.execute_reply":"2022-11-17T21:59:09.350239Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"256\n","output_type":"stream"}]},{"cell_type":"code","source":"path = os.getcwd()\nif not os.path.exists(path+'/training_data_final'):\n    shutil.copytree('../input/training-data-final/training_data_final', os.getcwd() + r'/training_data_final')\nprint(os.listdir(os.getcwd()))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:09.353230Z","iopub.execute_input":"2022-11-17T21:59:09.353995Z","iopub.status.idle":"2022-11-17T21:59:19.826884Z","shell.execute_reply.started":"2022-11-17T21:59:09.353957Z","shell.execute_reply":"2022-11-17T21:59:19.825840Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['training_data_final', '.virtual_documents', '__notebook_source__.ipynb']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Prepare the environment","metadata":{}},{"cell_type":"code","source":"train_split = 0.8\n\npath = os.getcwd()\nif not os.path.exists(path+'/training') and not os.path.exists(path+'/validation'):\n    os.mkdir(path+'/training')\n    os.mkdir(path+'/validation')\n\n    # Destination path \n    dest_train = path + '/training'\n    dest_valid = path + '/validation'\n\n    # Source path\n    source = path + '/training_data_final'\n\n    # Create train and validation into the training and validation folders\n    for folder in os.listdir(source):\n        if not os.path.exists(dest_train + '/' + folder):\n            os.mkdir(dest_train + '/' + folder)\n        if not os.path.exists(dest_valid + '/' + folder):\n            os.mkdir(dest_valid + '/' + folder)\n    \n        class_source = source + '/' + folder                                                   # Create path of the class\n        files = os.listdir(class_source)                                                       # List of files for the class\n        random.shuffle(files)                                                                  # Split is performed randomly\n        \n        # Create training set randomly\n        for i in range(int(len(files) * train_split)):\n            dest = shutil.copy(class_source+'/'+files[i], dest_train+'/'+folder+'/'+files[i])  # Copy an image in the training set\n        \n        # Create validation set randomly\n        for j in range(i + 1, len(files)):\n            dest = shutil.copy(class_source+'/'+files[j], dest_valid+'/'+folder+'/'+files[j])  # copy an image in the validation set","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:19.831136Z","iopub.execute_input":"2022-11-17T21:59:19.831436Z","iopub.status.idle":"2022-11-17T21:59:20.182714Z","shell.execute_reply.started":"2022-11-17T21:59:19.831409Z","shell.execute_reply":"2022-11-17T21:59:20.181707Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing function","metadata":{}},{"cell_type":"markdown","source":"Allows us to simply define a pipeline of preprocessing transformations","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.xception import preprocess_input\n\ndef preprocessing(image):\n    #return tf.image.adjust_saturation(image, 3)\n    return preprocess_input(image)\n    #return image","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:20.184298Z","iopub.execute_input":"2022-11-17T21:59:20.184687Z","iopub.status.idle":"2022-11-17T21:59:20.193209Z","shell.execute_reply.started":"2022-11-17T21:59:20.184648Z","shell.execute_reply":"2022-11-17T21:59:20.192172Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Prepare the training set for standardization","metadata":{}},{"cell_type":"code","source":"samples = []\ntargets = []\n\ndest_train = os.getcwd() + '/training'\n\nfor folder in os.listdir(dest_train):\n    dest_class = dest_train + '/' + folder\n    i = int(re.sub(\"\\D\", \"\", folder)) - 1\n    for img in os.listdir(dest_class):\n        temp = Image.open(dest_class + '/' + img).convert('RGB')\n        image = preprocessing(np.squeeze(np.expand_dims(temp, axis=0)))\n        label = tfk.utils.to_categorical(i, len(classes))\n        samples.append(image)\n        targets.append(label)\nX_train = np.array(samples)\ny_train = np.array(targets, dtype=np.uint8)\nprint(X_train.shape, X_train.dtype, sep=\", \")\nprint(y_train.shape, y_train.dtype, sep=\", \")\n\n# Compute the class weights in order to balance loss during training\ny_numeric = []\nfor v in y_train:\n    y_numeric.append(np.argmax(v))\n\nlabels = np.unique(np.fromiter([np.argmax(t) for t in y_train], np.int32))\n    \nclass_weights = dict(enumerate(class_weight.compute_class_weight('balanced', classes=labels, y=y_numeric)))\nprint(class_weights)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:20.195280Z","iopub.execute_input":"2022-11-17T21:59:20.196454Z","iopub.status.idle":"2022-11-17T21:59:22.476485Z","shell.execute_reply.started":"2022-11-17T21:59:20.196420Z","shell.execute_reply":"2022-11-17T21:59:22.475255Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(2829, 96, 96, 3), float32\n(2829, 8), uint8\n{0: 2.389358108108108, 1: 0.8320588235294117, 2: 0.8583131067961165, 3: 0.8667279411764706, 4: 0.8340212264150944, 5: 1.9978813559322033, 6: 0.8243006993006993, 7: 0.8709975369458128}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Static augmentation (only on training set)","metadata":{}},{"cell_type":"code","source":"static_aug = True\nbalanced = False\n\nif static_aug and not os.path.exists(path+'/training_aug'):\n    old_train = os.getcwd() + '/training'\n    dest_train = os.getcwd() + '/training_aug'\n    shutil.copytree(old_train, dest_train)\n\n    desired_amount = int(537 * train_split)\n\n    static_gen = ImageDataGenerator()\n\n    for folder in os.listdir(dest_train):\n        dest_path = dest_train + '/' + folder\n        label = int(re.sub(\"\\D\", \"\", folder)) - 1\n\n        if balanced:\n            to_produce = desired_amount - len(os.listdir(dest_path))\n        else:\n            class_expansion = [6, 1, 1, 1, 1, 3, 1, 4]\n            to_produce = (class_expansion[label] * desired_amount) - len(os.listdir(dest_path))\n        \n        static_gen_data = static_gen.flow_from_directory(dest_train,\n                                                        batch_size=1,\n                                                        target_size=input_size,\n                                                        classes=[folder],\n                                                        class_mode='categorical',      # Targets are directly converted into one-hot vectors\n                                                        shuffle=False,\n                                                        seed=seed) \n\n        print(f'Computing {to_produce} augmented images for target \"{folder}\"')\n        os.chdir(dest_path)\n        for i in range(0, to_produce):\n            Image.fromarray(np.squeeze(next(static_gen_data)[0]).astype(np.uint8)).save(f'aug{i:05}.jpg')\n        os.chdir('../')\n\n    os.chdir('../')\n    print('\\n' + os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:22.478694Z","iopub.execute_input":"2022-11-17T21:59:22.479444Z","iopub.status.idle":"2022-11-17T21:59:29.630848Z","shell.execute_reply.started":"2022-11-17T21:59:22.479400Z","shell.execute_reply":"2022-11-17T21:59:29.629723Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 406 images belonging to 1 classes.\nComputing 1310 augmented images for target \"Species8\"\nFound 177 images belonging to 1 classes.\nComputing 1110 augmented images for target \"Species6\"\nFound 429 images belonging to 1 classes.\nComputing 0 augmented images for target \"Species7\"\nFound 425 images belonging to 1 classes.\nComputing 4 augmented images for target \"Species2\"\nFound 408 images belonging to 1 classes.\nComputing 21 augmented images for target \"Species4\"\nFound 148 images belonging to 1 classes.\nComputing 2426 augmented images for target \"Species1\"\nFound 412 images belonging to 1 classes.\nComputing 17 augmented images for target \"Species3\"\nFound 424 images belonging to 1 classes.\nComputing 5 augmented images for target \"Species5\"\n\n/kaggle/working\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Online augmentation\nLets create the generators we'll need...","metadata":{}},{"cell_type":"code","source":"shift = 30\ntrain_data_gen = ImageDataGenerator(rotation_range=90,\n                                    width_shift_range=shift,\n                                    height_shift_range=shift,\n                                    horizontal_flip=True,\n                                    brightness_range=(0.8, 1.05),\n                                    #channel_shift_range=150,\n                                    zoom_range=[0.8, 1.3],\n                                    shear_range=0.1,\n                                    fill_mode='reflect',\n                                    preprocessing_function=preprocessing\n                                    #featurewise_std_normalization=True,\n                                    #featurewise_center=True, \n                                    #rescale=1./255\n                                    )\n\nvalid_data_gen = ImageDataGenerator(preprocessing_function=preprocessing\n                                    #featurewise_std_normalization=True,\n                                    #featurewise_center=True, \n                                    #rescale=1./255\n                                    )\n\n# Fit the standardization values\n#train_data_gen.fit(X_train)\n#valid_data_gen.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:29.632560Z","iopub.execute_input":"2022-11-17T21:59:29.632944Z","iopub.status.idle":"2022-11-17T21:59:29.639807Z","shell.execute_reply.started":"2022-11-17T21:59:29.632905Z","shell.execute_reply":"2022-11-17T21:59:29.638542Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"... using flow_from_directory","metadata":{}},{"cell_type":"code","source":"# Setting right paths\npath = os.getcwd()\nif static_aug:\n    training_dir = path + '/training_aug'\nelse:\n    training_dir = path + '/training'\nvalidation_dir = path + '/validation'\n\n# Training\ntrain_gen = train_data_gen.flow_from_directory(training_dir,\n                                               batch_size=batch_size,\n                                               target_size=input_size,\n                                               classes=classes,\n                                               class_mode='categorical',\n                                               shuffle=True,\n                                               seed=seed)  \n\n# Validation\nvalid_gen = valid_data_gen.flow_from_directory(validation_dir,\n                                               batch_size=batch_size, \n                                               target_size=input_size,\n                                               classes=classes,\n                                               class_mode='categorical',\n                                               shuffle=False,\n                                               seed=seed)\n\n# Disable AutoShard\noptions = tf.data.Options()\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n\n# Create Datasets objects\ntrain_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n                                               output_types=(tf.float16, tf.uint8),\n                                               output_shapes=([None, input_shape[0], input_shape[1], input_shape[2]], [None, len(classes)]))\n\ntrain_dataset = train_dataset.with_options(options)\ntrain_dataset = train_dataset.repeat()\n\nvalid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n                                               output_types=(tf.float16, tf.uint8),\n                                               output_shapes=([None, input_shape[0], input_shape[1], input_shape[2]], [None, len(classes)]))\n\nvalid_dataset = valid_dataset.with_options(options)\nvalid_dataset = valid_dataset.repeat()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:29.641676Z","iopub.execute_input":"2022-11-17T21:59:29.642396Z","iopub.status.idle":"2022-11-17T21:59:30.038497Z","shell.execute_reply.started":"2022-11-17T21:59:29.642361Z","shell.execute_reply":"2022-11-17T21:59:30.037558Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 7722 images belonging to 8 classes.\nFound 713 images belonging to 8 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Prepare the validation set for evaluation purposes","metadata":{}},{"cell_type":"code","source":"samples = []\ntargets = []\n\n#mean = train_data_gen.mean\n#std = train_data_gen.std\n\ndest_valid = os.getcwd() + '/validation'\n\nfor folder in os.listdir(dest_valid):\n    dest_class = dest_valid + '/' + folder\n    i = int(re.sub(\"\\D\", \"\", folder)) - 1\n    for img in os.listdir(dest_class):\n        temp = Image.open(dest_class + '/' + img).convert('RGB')\n        #image = preprocessing((np.squeeze(np.expand_dims(temp, axis=0)) - mean) / std)\n        image = preprocessing(np.squeeze(np.expand_dims(temp, axis=0)))\n        label = tfk.utils.to_categorical(i, len(classes))\n        samples.append(image)\n        targets.append(label)\n\nX_val = np.array(samples, dtype=np.float16)\ny_val = np.array(targets, dtype=np.uint8)\nprint(X_val.shape, X_val.dtype, sep=\", \")\nprint(y_val.shape, y_val.dtype, sep=\", \")","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:30.042356Z","iopub.execute_input":"2022-11-17T21:59:30.042646Z","iopub.status.idle":"2022-11-17T21:59:30.643801Z","shell.execute_reply.started":"2022-11-17T21:59:30.042619Z","shell.execute_reply":"2022-11-17T21:59:30.642581Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(713, 96, 96, 3), float16\n(713, 8), uint8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Models definition functions","metadata":{}},{"cell_type":"code","source":"def build_tl_model(input_shape):\n    tf.random.set_seed(seed)\n    \n    inflated_dim0 = int(inflation_coeff * input_shape[0])\n    inflated_dim1 = int(inflation_coeff * input_shape[1])\n    inflated_shape = (inflated_dim0, inflated_dim1, 3)\n\n    # Load the supernet\n    supernet = tfk.applications.Xception(include_top=False,\n                                         weights=\"imagenet\",\n                                         input_shape=inflated_shape)\n    \n    # Build the neural network layer by layer\n    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n    \n    x = tfkl.Resizing(inflated_dim0, inflated_dim1, interpolation=\"bicubic\", name='resizing')(input_layer)\n    \n    x = supernet(x)\n\n    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n    #x = tfkl.Flatten(name='flatten')(x)\n\n    x = tfkl.Dropout(0.3, seed=seed, name='dropout')(x)\n    \n    output_layer = tfkl.Dense(\n        units = len(classes), \n        activation = 'softmax', \n        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n        name = 'output_layer')(x)\n    \n    # Connect input and output through the Model class\n    model = tfk.Model(inputs = input_layer, outputs = output_layer, name = 'tl_model')\n\n    # Compile the model\n    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(2e-4), metrics='accuracy')\n\n    # Return the model\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:30.645259Z","iopub.execute_input":"2022-11-17T21:59:30.645959Z","iopub.status.idle":"2022-11-17T21:59:30.655393Z","shell.execute_reply.started":"2022-11-17T21:59:30.645919Z","shell.execute_reply":"2022-11-17T21:59:30.654337Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Build the model","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    model = build_tl_model(input_shape)\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:30.656724Z","iopub.execute_input":"2022-11-17T21:59:30.658384Z","iopub.status.idle":"2022-11-17T21:59:35.909155Z","shell.execute_reply.started":"2022-11-17T21:59:30.658354Z","shell.execute_reply":"2022-11-17T21:59:35.908089Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83683744/83683744 [==============================] - 0s 0us/step\nModel: \"tl_model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_layer (InputLayer)    [(None, 96, 96, 3)]       0         \n                                                                 \n resizing (Resizing)         (None, 144, 144, 3)       0         \n                                                                 \n xception (Functional)       (None, 5, 5, 2048)        20861480  \n                                                                 \n gap (GlobalAveragePooling2D  (None, 2048)             0         \n )                                                               \n                                                                 \n dropout (Dropout)           (None, 2048)              0         \n                                                                 \n output_layer (Dense)        (None, 8)                 16392     \n                                                                 \n=================================================================\nTotal params: 20,877,872\nTrainable params: 20,823,344\nNon-trainable params: 54,528\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train the model","metadata":{}},{"cell_type":"code","source":"train_mul = 1\n\n'''\nhigh_period = 5\nmedium_period = 10\nlow_period = 5\n\nhigh_lr = 5e-4  \nmedium_lr = 1e-4\nlow_lr = 2e-5\n\ndef scheduler(epoch, lr):\n    global medium_lr, high_lr\n\n    #convergence factor to shrink high and medium values onto low_lr over time\n    tot_period = high_period + medium_period + low_period + medium_period\n    if epoch % (tot_period) == (tot_period - 1):\n        high_lr = max(high_lr * tf.math.exp(-0.1), low_lr)\n        medium_lr = max(medium_lr * tf.math.exp(-0.1), low_lr)\n\n    if epoch % (tot_period) < high_period:\n        return high_lr\n    elif epoch % (tot_period) < high_period + medium_period:\n        return medium_lr    \n    elif epoch % (tot_period) < high_period + medium_period + low_period:\n        return low_lr    \n    return medium_lr\n'''\n\ndecay_rate = 5  # patience should be set: changes_to_see * decay_rate + 1\nmin_lr = 2e-5\n\ndef scheduler(epoch, lr):\n    if epoch % decay_rate == (decay_rate - 1):\n        return max(lr * tf.math.exp(-0.1), min_lr)\n    return lr\n\nstart = time.time()\n\nclass ElapsedTimeCallback(tfk.callbacks.Callback):\n    def on_test_end(self, epoch, logs=None):\n        el = time.time() - start\n        print(f'\\nElapsed time: {int(el // 60)} minutes {(el % 60):.3f} seconds')\n\nhistory = model.fit(x=train_dataset,\n                    epochs=epochs,                                     # Only indicative since we set \"repeat\" in training and validation datasets\n                    steps_per_epoch=int(len(train_gen) * train_mul),\n                    validation_data=valid_dataset,\n                    validation_steps=len(valid_gen),\n                    class_weight=class_weights,\n                    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=21, restore_best_weights=True),\n                                 tfk.callbacks.LearningRateScheduler(scheduler),\n                                 ElapsedTimeCallback()]\n).history","metadata":{"execution":{"iopub.status.busy":"2022-11-17T21:59:35.910898Z","iopub.execute_input":"2022-11-17T21:59:35.911651Z","iopub.status.idle":"2022-11-17T22:02:51.407903Z","shell.execute_reply.started":"2022-11-17T21:59:35.911611Z","shell.execute_reply":"2022-11-17T22:02:51.406021Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/400\n","output_type":"stream"},{"name":"stderr","text":"2022-11-17 22:00:11.133040: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n2022-11-17 22:00:11.617274: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n2022-11-17 22:00:12.775118: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n2022-11-17 22:00:13.863256: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n","output_type":"stream"},{"name":"stdout","text":"31/31 [==============================] - ETA: 0s - loss: 1.8707 - accuracy: 0.4628\nElapsed time: 1 minutes 19.922 seconds\n31/31 [==============================] - 81s 1s/step - loss: 1.8707 - accuracy: 0.4628 - val_loss: 2.1039 - val_accuracy: 0.2398 - lr: 2.0000e-04\nEpoch 2/400\n31/31 [==============================] - ETA: 0s - loss: 0.8841 - accuracy: 0.6966\nElapsed time: 1 minutes 53.883 seconds\n31/31 [==============================] - 34s 1s/step - loss: 0.8841 - accuracy: 0.6966 - val_loss: 1.6262 - val_accuracy: 0.4670 - lr: 2.0000e-04\nEpoch 3/400\n31/31 [==============================] - ETA: 0s - loss: 0.5711 - accuracy: 0.8087\nElapsed time: 2 minutes 29.730 seconds\n31/31 [==============================] - 36s 1s/step - loss: 0.5711 - accuracy: 0.8087 - val_loss: 1.5818 - val_accuracy: 0.4881 - lr: 2.0000e-04\nEpoch 4/400\n31/31 [==============================] - ETA: 0s - loss: 0.4112 - accuracy: 0.8592\nElapsed time: 3 minutes 5.830 seconds\n31/31 [==============================] - 36s 1s/step - loss: 0.4112 - accuracy: 0.8592 - val_loss: 1.4007 - val_accuracy: 0.5820 - lr: 2.0000e-04\nEpoch 5/400\n 7/31 [=====>........................] - ETA: 26s - loss: 0.3294 - accuracy: 0.8934","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/1353397242.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=21, restore_best_weights=True),\n\u001b[1;32m     25\u001b[0m                                  \u001b[0mtfk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                  ElapsedTimeCallback()]\n\u001b[0m\u001b[1;32m     27\u001b[0m ).history\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                         ):\n\u001b[1;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2497\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1863\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"### Plot training results","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history['loss'], label='Std training', alpha=.3, color='#ff7f0e', linestyle='--')\nplt.plot(history['val_loss'], label='Std validation', alpha=.8, color='#ff7f0e')\nplt.legend(loc='upper left')\nplt.title('Categorical Crossentropy')\nplt.grid(alpha=.3)\n\nplt.figure(figsize=(15,5))\nplt.plot(history['accuracy'], label='Std training', alpha=.8, color='#ff7f0e', linestyle='--')\nplt.plot(history['val_accuracy'], label='Std validation', alpha=.8, color='#ff7f0e')\nplt.legend(loc='upper right')\nplt.title('Accuracy')\nplt.grid(alpha=.3)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:02:51.409307Z","iopub.status.idle":"2022-11-17T22:02:51.410251Z","shell.execute_reply.started":"2022-11-17T22:02:51.409927Z","shell.execute_reply":"2022-11-17T22:02:51.409969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot the confusion matrix (evaluated on the validation set)","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(X_val)\ncm = confusion_matrix(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\n\naccuracy = accuracy_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\nprecision = precision_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\nrecall = recall_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\nf1 = f1_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average=None)\nprint('Accuracy:',accuracy.round(4))\nprint('Precision:',precision.round(4))\nprint('Recall:',recall.round(4))\nprint('F1:',f1.round(4))\n\nplt.figure(figsize=(10,8))\nsns.heatmap(cm.T, xticklabels=classes, yticklabels=classes)\nplt.xlabel('True labels')\nplt.ylabel('Predicted labels')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:02:51.411901Z","iopub.status.idle":"2022-11-17T22:02:51.414080Z","shell.execute_reply.started":"2022-11-17T22:02:51.413769Z","shell.execute_reply":"2022-11-17T22:02:51.413798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save the model","metadata":{}},{"cell_type":"code","source":"model.save('best_model', include_optimizer=False)\n\nshutil.make_archive('best_model', 'zip', 'best_model')\nFileLink(r'best_model.zip')","metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:03:01.538311Z","iopub.execute_input":"2022-11-17T22:03:01.539048Z","iopub.status.idle":"2022-11-17T22:03:29.919523Z","shell.execute_reply.started":"2022-11-17T22:03:01.538989Z","shell.execute_reply":"2022-11-17T22:03:29.918546Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/best_model.zip","text/html":"<a href='best_model.zip' target='_blank'>best_model.zip</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Improve the classifier module of the previously trained supernet","metadata":{}},{"cell_type":"code","source":"def build_classifier_model(input_shape):\n    tf.random.set_seed(seed)\n    \n    inflated_dim0 = int(inflation_coeff * input_shape[0])\n    inflated_dim1 = int(inflation_coeff * input_shape[1])\n    inflated_shape = (inflated_dim0, inflated_dim1, 3)\n\n    # Load the supernet\n    supernet = tfk.applications.Xception(include_top=False,\n                                         input_shape=inflated_shape)\n\n    # Recover previous weights\n    supernet.set_weights(tfk.models.load_model('best_model').get_layer('xception').get_weights())\n    \n    # Use the supernet only as feature extractor\n    supernet.trainable = False  # \"True\" for fine tuning\n    for i, layer in enumerate(supernet.layers[:-25]):\n      layer.trainable = False\n      #print(i, layer.name, layer.trainable)\n    \n    # Build the neural network layer by layer\n    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n    \n    x = tfkl.Resizing(inflated_dim0, inflated_dim1, interpolation=\"bicubic\", name='resizing')(input_layer)\n    \n    x = supernet(x)\n\n    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n    \n    x_gap = x\n\n    x = tfkl.Dropout(0.3, seed=seed, name='dropout')(x)\n\n    x = tfkl.Dense(\n        units = 2048,  \n        activation = 'relu',\n        kernel_initializer = tfk.initializers.HeUniform(seed),\n        name = 'classifier')(x)\n\n    # Skip connection\n    x = tfkl.Add(name='adder')([x_gap, x])\n    \n    output_layer = tfkl.Dense(\n                   units = len(classes), \n                   activation = 'softmax', \n                   kernel_initializer = tfk.initializers.GlorotUniform(seed),\n                   name = 'output_layer')(x)\n    \n    # Connect input and output through the Model class\n    model = tfk.Model(inputs = input_layer, outputs = output_layer, name = 'classifier_model')\n\n    # Compile the model\n    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(3e-4), metrics='accuracy')\n\n    # Return the model\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:10:45.336113Z","iopub.execute_input":"2022-11-17T22:10:45.336491Z","iopub.status.idle":"2022-11-17T22:10:45.349200Z","shell.execute_reply.started":"2022-11-17T22:10:45.336460Z","shell.execute_reply":"2022-11-17T22:10:45.348003Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    classifier_model = build_classifier_model(input_shape)\n    classifier_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:10:50.120808Z","iopub.execute_input":"2022-11-17T22:10:50.121180Z","iopub.status.idle":"2022-11-17T22:11:05.349255Z","shell.execute_reply.started":"2022-11-17T22:10:50.121149Z","shell.execute_reply":"2022-11-17T22:11:05.348258Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Model: \"classifier_model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_layer (InputLayer)       [(None, 96, 96, 3)]  0           []                               \n                                                                                                  \n resizing (Resizing)            (None, 144, 144, 3)  0           ['input_layer[0][0]']            \n                                                                                                  \n xception (Functional)          (None, 5, 5, 2048)   20861480    ['resizing[0][0]']               \n                                                                                                  \n gap (GlobalAveragePooling2D)   (None, 2048)         0           ['xception[0][0]']               \n                                                                                                  \n dropout (Dropout)              (None, 2048)         0           ['gap[0][0]']                    \n                                                                                                  \n classifier2 (Dense)            (None, 2048)         4196352     ['dropout[0][0]']                \n                                                                                                  \n adder (Add)                    (None, 2048)         0           ['gap[0][0]',                    \n                                                                  'classifier2[0][0]']            \n                                                                                                  \n output_layer (Dense)           (None, 8)            16392       ['adder[0][0]']                  \n                                                                                                  \n==================================================================================================\nTotal params: 25,074,224\nTrainable params: 4,212,744\nNon-trainable params: 20,861,480\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_mul = 1\n\nstart = time.time()\n\nclassifier_history = classifier_model.fit(x=train_dataset,\n                                          epochs=epochs,                                  \n                                          steps_per_epoch=int(len(train_gen) * train_mul),\n                                          validation_data=valid_dataset,\n                                          validation_steps=len(valid_gen),\n                                          class_weight=class_weights,\n                                          callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=26, restore_best_weights=True),\n                                                       tfk.callbacks.LearningRateScheduler(scheduler),\n                                                       ElapsedTimeCallback()]\n).history","metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:11:41.907882Z","iopub.execute_input":"2022-11-17T22:11:41.908247Z","iopub.status.idle":"2022-11-17T22:12:56.948888Z","shell.execute_reply.started":"2022-11-17T22:11:41.908215Z","shell.execute_reply":"2022-11-17T22:12:56.944939Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/400\n31/31 [==============================] - ETA: 0s - loss: 0.6699 - accuracy: 0.7919\nElapsed time: 0 minutes 47.277 seconds\n","output_type":"stream"},{"name":"stderr","text":"2022-11-17 22:12:29.813868: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 16777216 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"31/31 [==============================] - 48s 1s/step - loss: 0.6699 - accuracy: 0.7919 - val_loss: 0.8404 - val_accuracy: 0.7209 - lr: 3.0000e-04\nEpoch 2/400\n","output_type":"stream"},{"name":"stderr","text":"2022-11-17 22:12:30.296165: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 16777216 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"29/31 [===========================>..] - ETA: 1s - loss: 0.4550 - accuracy: 0.8473","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/3570145466.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                           callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=26, restore_best_weights=True),\n\u001b[1;32m     12\u001b[0m                                                        \u001b[0mtfk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                                        ElapsedTimeCallback()]\n\u001b[0m\u001b[1;32m     14\u001b[0m ).history\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                         ):\n\u001b[1;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2497\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1863\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"### Plot training results","metadata":{}},{"cell_type":"code","source":"history = classifier_history\n\nplt.figure(figsize=(15,5))\nplt.plot(history['loss'], label='Std training', alpha=.3, color='#ff7f0e', linestyle='--')\nplt.plot(history['val_loss'], label='Std validation', alpha=.8, color='#ff7f0e')\nplt.legend(loc='upper left')\nplt.title('Categorical Crossentropy')\nplt.grid(alpha=.3)\n\nplt.figure(figsize=(15,5))\nplt.plot(history['accuracy'], label='Std training', alpha=.8, color='#ff7f0e', linestyle='--')\nplt.plot(history['val_accuracy'], label='Std validation', alpha=.8, color='#ff7f0e')\nplt.legend(loc='upper right')\nplt.title('Accuracy')\nplt.grid(alpha=.3)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:02:51.435285Z","iopub.status.idle":"2022-11-17T22:02:51.435792Z","shell.execute_reply.started":"2022-11-17T22:02:51.435488Z","shell.execute_reply":"2022-11-17T22:02:51.435525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot the confusion matrix (evaluated on the validation set)","metadata":{}},{"cell_type":"code","source":"predictions = classifier_model.predict(X_val)\ncm = confusion_matrix(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\n\naccuracy = accuracy_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\nprecision = precision_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\nrecall = recall_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\nf1 = f1_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average=None)\nprint('Accuracy:',accuracy.round(4))\nprint('Precision:',precision.round(4))\nprint('Recall:',recall.round(4))\nprint('F1:',f1.round(4))\n\nplt.figure(figsize=(10,8))\nsns.heatmap(cm.T, xticklabels=classes, yticklabels=classes)\nplt.xlabel('True labels')\nplt.ylabel('Predicted labels')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:02:51.439336Z","iopub.status.idle":"2022-11-17T22:02:51.439894Z","shell.execute_reply.started":"2022-11-17T22:02:51.439610Z","shell.execute_reply":"2022-11-17T22:02:51.439636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save the model","metadata":{}},{"cell_type":"code","source":"classifier_model.save('best_model_improved', include_optimizer=False)\n\nshutil.make_archive('best_model_improved', 'zip', 'best_model_improved')\nFileLink(r'best_model_improved.zip')","metadata":{"execution":{"iopub.status.busy":"2022-11-17T22:02:51.447340Z","iopub.status.idle":"2022-11-17T22:02:51.447962Z","shell.execute_reply.started":"2022-11-17T22:02:51.447631Z","shell.execute_reply":"2022-11-17T22:02:51.447660Z"},"trusted":true},"execution_count":null,"outputs":[]}]}